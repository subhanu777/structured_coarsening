{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53a1e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as skd\n",
    "import sklearn.metrics as skm\n",
    "from time import *\n",
    "from tqdm import tqdm\n",
    "def A_to_L(A):\n",
    "    D=np.diag(np.sum(A,axis=0))\n",
    "    return D-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf29680f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#First, we use the spectralGraphTopology to denoise laplacian matrices polluted with noise. \n",
    "# We generate a 4 components adjacency matrix\n",
    "\n",
    "\n",
    "\n",
    "n_class_feats = 5\n",
    "n_classes = 4\n",
    "n_feats = n_classes * n_class_feats\n",
    "prob_intra = 1\n",
    "prob_extra = 0.3\n",
    "max_weight_intra = 1\n",
    "max_weight_extra = 0.3\n",
    "adj = np.zeros((n_feats, n_feats))\n",
    "for i in range(n_classes):\n",
    "    i_start = i * n_class_feats\n",
    "    i_end = i_start + n_class_feats\n",
    "    for ii in range(i_start, i_end):\n",
    "        for jj in range(ii+1, i_end):\n",
    "            adj[ii, jj] = np.random.binomial(n=1, p=prob_intra) * np.random.uniform(high=max_weight_intra)\n",
    "plt.matshow(adj+adj.T)\n",
    "plt.title(\"Original matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b044de2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(n_feats):\n",
    "    for j in range(i+1, n_feats):\n",
    "        adj[i, j] += np.random.binomial(n=1, p=prob_extra) * np.random.uniform(high=max_weight_extra)\n",
    "adj = adj + adj.T\n",
    "plt.matshow(adj)\n",
    "plt.title(\"Noisy matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5518072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helpers\n",
    "import numpy as np\n",
    "from sklearn.isotonic import *\n",
    "from numba import njit\n",
    "\n",
    "# Computes the Adjacency linear operator which maps a vector of weights into\n",
    "# a valid Adjacency matrix.\n",
    "# @param w weight vector of the graph\n",
    "# @return Aw the Adjacency matrix\n",
    "def Ad(v):#TODO check new version still works\n",
    "    \"\"\"take an p(p-1)//2 array and return the adjacency matrice\"\"\"\n",
    "    p=1\n",
    "    while (p*(p-1))//2!=v.shape[0]:\n",
    "        p+=1\n",
    "    a = np.zeros([p,p])\n",
    "    s=0\n",
    "    for nb in range(p-1,0,-1):\n",
    "        i=p-1-nb\n",
    "        a[i][i+1:]=v[s:s+p-i-1]\n",
    "        \"\"\"for j in range(i+1,p):\n",
    "            a[i][j] = v[s+j-i-1]\n",
    "            a[j][i] = v[s+j-i-1]\"\"\"\n",
    "        s += nb\n",
    "    a+=a.T\n",
    "    return a\n",
    "\n",
    "# Computes the Laplacian linear operator which maps a vector of weights into a valid Laplacian matrix.\n",
    "# @param w weight vector of the graph\n",
    "# @return Lw the Laplacian matrix\n",
    "def La(v):\n",
    "    a = -Ad(v)\n",
    "    for k in range(a.shape[0]):\n",
    "        a[k][k]=-np.sum(a[k])\n",
    "    return a\n",
    "\n",
    "@njit\n",
    "def Lstar(M):\n",
    "  \"\"\"\n",
    "  Compute the adjoint operator of L\n",
    "  \"\"\"\n",
    "  N = M.shape[1]\n",
    "  k = (N * (N - 1)) // 2\n",
    "  j, l = 0, 1\n",
    "  w = np.zeros(k)\n",
    "  for i in np.arange(k):\n",
    "    w[i] = M[j, j] + M[l, l] - (M[l, j] + M[j, l])\n",
    "    if (l == (N - 1)):\n",
    "        j += 1\n",
    "        l = j + 1\n",
    "    else:\n",
    "      l += 1\n",
    "  return w\n",
    "\n",
    "#Computes the matrix form of the composition of the operators Lstar and\n",
    "# L, i.e., Lstar o L.\n",
    "#\n",
    "# @param n number of columns/rows\n",
    "# @return M the composition of Lstar and L\n",
    "def Mmat(n):\n",
    "  e = np.zeros(n)\n",
    "  M = np.zeros([n, n])\n",
    "  e[0] = 1\n",
    "  M[0] = Lstar(La(e))\n",
    "  for j in np.arange(1,n):\n",
    "    e[j - 1] = 0\n",
    "    e[j] = 1\n",
    "    M[j] = Lstar(L(e))\n",
    "  return M.T\n",
    "\n",
    "@njit\n",
    "def Astar(M):\n",
    "  N = M.shape[1]\n",
    "  k = (N * (N - 1))//2\n",
    "  j = 0\n",
    "  l = 1\n",
    "  w=np.zeros(k)\n",
    "\n",
    "  for i in np.arange(k):\n",
    "    w[i] = M[l, j] + M[j, l]\n",
    "    if l == (N - 1):\n",
    "      j+=1\n",
    "      l = j+1\n",
    "    else:\n",
    "      l+=1\n",
    "  return w\n",
    "\n",
    "\n",
    "# Computes the matrix form of the composition of the operators Astar and\n",
    "# A, i.e., Astar o A.\n",
    "def Pmat(n):\n",
    "  e = np.zeros(n)\n",
    "  M = np.zeros([n, n])\n",
    "  e[0] = 1;\n",
    "  M[0] = Astar(Ad(e))\n",
    "  for j in np.arange(1,n):\n",
    "    e[j - 1] = 0\n",
    "    e[j] = 1\n",
    "    M[j] = Astar(A(e))\n",
    "  return M.T\n",
    "\n",
    "def vec(M):\n",
    "  return M.T.flatten()\n",
    "\n",
    "def vecLmat(n):\n",
    "  ncols = (n * (n - 1))//2\n",
    "  nrows = n * n\n",
    "\n",
    "  e = np.zeros(ncols)\n",
    "  R = np.zeros([nrows,ncols])\n",
    "  e[0] = 1;\n",
    "  R[0] = vec(L(e));\n",
    "  for j in np.arange(1,ncols):\n",
    "    e[j - 1] = 0;\n",
    "    e[j] = 1;\n",
    "    R[j] = vec(L(e));\n",
    "  return R.T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Computes the inverse of the L operator.\n",
    "\n",
    "# @param M Laplacian matrix\n",
    "# @return w the weight vector of the graph\n",
    "def Linv(M):\n",
    "  n = M.shape[0]\n",
    "  return np.concatenate([-M[i][i+1:] for i in np.arange(n)])\n",
    "\n",
    "#get the n(n-1)//2 vector from the laplacian(or A?)\n",
    "#M is laplacian\n",
    "#w is weight vector\n",
    "def Ainv(M):\n",
    "  n = M.shape[0]\n",
    "  return np.concatenate([M[i][i+1:] for i in np.arange(n)])\n",
    "\n",
    "\n",
    "def isoreg(y):\n",
    "    \"\"\"\n",
    "    Compute the isotonic regression of a vector y\n",
    "    For compatibity reasons, we chosse an arbitrary x as training data\n",
    "    but x is useless as we only keep the estimates of the y_i and never interpolate\n",
    "    \"\"\"\n",
    "    x = np.arange(len(y))\n",
    "    isoreg = IsotonicRegression()\n",
    "    isoreg.fit(x, y)\n",
    "    return isoreg.f_(x)\n",
    "\n",
    "\n",
    "\n",
    "def w_init(w0, Sinv):\n",
    "  \"\"\"\n",
    "  Initialize w0, the vectorized upper triangular coefficients of the adjacency matrix\n",
    "  \"\"\"\n",
    "  if type(w0) is str:\n",
    "    if (w0 == \"qp\"):\n",
    "      R = vecLmat(Sinv.shape[1])\n",
    "      qp = 0\n",
    "      assert False,\"idk\"\n",
    "      #quadprog::solve.QP(crossprod(R), t(R) %*% vec(Sinv), diag(ncol(R)))\n",
    "      w0 = qp#qp$solution\n",
    "    elif (w0 == \"naive\"):\n",
    "      w0 = Linv(Sinv)\n",
    "      w0[w0 < 0] = 0 # Should not happen\n",
    "  return w0\n",
    "\n",
    "\n",
    "\n",
    "def laplacian_w_update(w, Lw, U, beta, lambd, K, p):\n",
    "  \"\"\"\n",
    "  Update w according to equation 38\n",
    "  \"\"\"\n",
    "  t = lambd[:, None]**0.5 * U.T\n",
    "  c = Lstar(t.T@t - K / beta)\n",
    "  grad_f = Lstar(Lw) - c\n",
    "  if 1:\n",
    "    M_grad_f = - Lstar(La(grad_f))\n",
    "    wT_M_grad_f = np.sum(w * M_grad_f)\n",
    "    dwT_M_dw = np.sum(grad_f * M_grad_f)\n",
    "  # exact line search\n",
    "    t = (wT_M_grad_f - np.sum(c * grad_f)) / dwT_M_dw\n",
    "  else:\n",
    "      t=1/(2*p)\n",
    "  w_update = w - t * grad_f\n",
    "  w_update[w_update < 0] = 0\n",
    "  return w_update\n",
    "\n",
    "\n",
    "\n",
    "def joint_w_update(w, Lw, Aw, U, V, lambd, psi, beta, nu, K):\n",
    "  t=lambd[:, None]**0.5*U.T\n",
    "  ULmdUT = t.T@t\n",
    "  VPsiVT = V @ np.diag(psi) @ V.T\n",
    "  c1 = Lstar(beta * ULmdUT - K)\n",
    "  c2 = nu * Astar(VPsiVT)\n",
    "  Mw = Lstar(Lw)\n",
    "  Pw = 2 * w\n",
    "  grad_f1 = beta * Mw - c1\n",
    "  M_grad_f1 = Lstar(La(grad_f1))\n",
    "  grad_f2 = nu * Pw - c2\n",
    "  P_grad_f2 = 2 * grad_f2\n",
    "  grad_f = grad_f1 + grad_f2\n",
    "  t = np.sum((beta * Mw + nu * Pw - (c1 + c2)) * grad_f) / np.sum(grad_f * (beta * M_grad_f1 + nu * P_grad_f2))\n",
    "  w_update = w - t * (grad_f1 + grad_f2)\n",
    "  w_update[w_update < 0] = 0\n",
    "  return w_update\n",
    "\n",
    "\n",
    "def bipartite_w_update(w, Aw, V, nu, psi, K, J, Lips):\n",
    "  reg_eps = 0\n",
    "  grad_h = 2 * w - Astar(V @ np.diag(psi) @ V.T) #+ Lstar(K) / beta#\n",
    "  w_update = w - (Lstar(np.linalg.inv(La(w) + J+np.eye(J.shape[0])*reg_eps) + K) + nu * grad_h) / (2 * nu + Lips)\n",
    "  w_update[w_update < 0] = 0#TODO faire en sorte que la régularisation ligne précédent ne soit pas nécessaire\n",
    "  return w_update\n",
    "\n",
    "\n",
    "\n",
    "def laplacian_U_update(Lw, k):\n",
    "  \"\"\"\n",
    "  Return all but the k first eigenvectors of the Laplacian Lw\n",
    "  \"\"\"\n",
    "  return np.linalg.eigh(Lw)[1][:, k:]\n",
    "\n",
    "\n",
    "def bipartite_V_update(Aw, z):\n",
    "  n = Aw.shape[1]\n",
    "  V = np.linalg.eigh(Aw)[1]\n",
    "  return np.concatenate([V[:, :(n - z)//2], V[:,(n + z)//2:n]],axis=1)\n",
    "\n",
    "\n",
    "def joint_U_update(Lw,k):\n",
    "  return np.linalg.eigh(Lw)[1][:, k:]\n",
    "\n",
    "\n",
    "def joint_V_update(Aw,z):\n",
    "  return bipartite_V_update(Aw,z)\n",
    "\n",
    "\n",
    "\n",
    "def laplacian_lambda_update(lb, ub, beta, U, Lw, k):\n",
    "  \"\"\"\n",
    "  Update lambda according to algorithm 1\n",
    "  \"\"\"\n",
    "  q = Lw.shape[1] - k\n",
    "  d = np.diagonal(U.T @ Lw @ U)\n",
    "  # unconstrained solution as initial point\n",
    "  lambd = .5 * (d + (d**2 + 4 / beta)**0.5)\n",
    "  eps = 1e-9\n",
    "  condition_ub = np.array([(lambd[q-1] - ub) <= eps])\n",
    "  condition_lb = np.array([(lambd[0] - lb) >= -eps])\n",
    "  condition_ordered = (lambd[1:q] - lambd[0:(q-1)]) >= -eps\n",
    "  condition = np.concatenate([condition_ub,\\\n",
    "                 condition_lb,\\\n",
    "                 condition_ordered])\n",
    "  if np.all(condition):\n",
    "    return lambd\n",
    "  else:\n",
    "    greater_ub = lambd > ub\n",
    "    lesser_lb = lambd < lb\n",
    "    lambd[greater_ub] = ub\n",
    "    lambd[lesser_lb] = lb\n",
    "  condition_ub = np.array([(lambd[q-1] - ub) <= eps])\n",
    "  condition_lb = np.array([(lambd[0] - lb) >= -eps])\n",
    "  condition_ordered = (lambd[1:q] - lambd[:(q-1)]) >= -eps\n",
    "  condition = np.concatenate([condition_ub,\\\n",
    "                 condition_lb,\\\n",
    "                 condition_ordered])\n",
    "  if np.all(condition):\n",
    "    return (lambd)\n",
    "  else:\n",
    "    print(lambd)\n",
    "    raise ValueError('eigenvalues are not in increasing order consider increasing the value of beta')\n",
    "\n",
    "\n",
    "def bipartite_psi_update(V, Aw, lb = -np.inf, ub = np.inf):\n",
    "  c = np.diagonal(V.T @ Aw @ V)\n",
    "  n = c.shape[0]\n",
    "  c_tilde = .5 * (c[(n//2):][::-1] - c[:(n//2)])\n",
    "  x = isoreg(c_tilde[::-1])\n",
    "  #x <- stats::isoreg(rev(c_tilde))$yf # R\n",
    "  x = np.concatenate((-x[::-1], x))\n",
    "  #x <- c(-rev(x), x) # R\n",
    "  x[x < lb] = lb\n",
    "  x[x > ub] = ub\n",
    "  return x\n",
    "\n",
    "\n",
    "def Ad(v):#TODO check new version still works\n",
    "    \"\"\"take an p(p-1)//2 array and return the adjacency matrice\"\"\"\n",
    "    p=1\n",
    "    while (p*(p-1))//2!=v.shape[0]:\n",
    "        p+=1\n",
    "    a = np.zeros([p,p])\n",
    "    s=0\n",
    "    for nb in range(p-1,0,-1):\n",
    "        i=p-1-nb\n",
    "        a[i][i+1:]=v[s:s+p-i-1]\n",
    "        \"\"\"for j in range(i+1,p):\n",
    "            a[i][j] = v[s+j-i-1]\n",
    "            a[j][i] = v[s+j-i-1]\"\"\"\n",
    "        s += nb\n",
    "    a+=a.T\n",
    "    return a\n",
    "\n",
    "\n",
    "def La(v):\n",
    "    a = -Ad(v)\n",
    "    for k in range(a.shape[0]):\n",
    "        a[k][k]=-np.sum(a[k])\n",
    "    return a\n",
    "\n",
    "\n",
    "def Linv(M):\n",
    "  n = M.shape[0]\n",
    "  return np.concatenate([-M[i][i+1:] for i in np.arange(n)])\n",
    "\n",
    "#get the n(n-1)//2 vector from the laplacian(or A?)\n",
    "#M is laplacian\n",
    "#w is weight vector\n",
    "def Ainv(M):\n",
    "  n = M.shape[0]\n",
    "  return np.concatenate([M[i][i+1:] for i in np.arange(n)])\n",
    "\n",
    "\n",
    "\n",
    "def w_init(w0, Sinv):\n",
    "  \"\"\"\n",
    "  Initialize w0, the vectorized upper triangular coefficients of the adjacency matrix\n",
    "  \"\"\"\n",
    "  if type(w0) is str:\n",
    "    if (w0 == \"qp\"):\n",
    "      R = vecLmat(Sinv.shape[1])\n",
    "      qp = 0\n",
    "      assert False,\"idk\"\n",
    "      #quadprog::solve.QP(crossprod(R), t(R) %*% vec(Sinv), diag(ncol(R)))\n",
    "      w0 = qp#qp$solution\n",
    "    elif (w0 == \"naive\"):\n",
    "      w0 = Linv(Sinv)\n",
    "      w0[w0 < 0] = 0 # Should not happen\n",
    "  return w0\n",
    "\n",
    "\n",
    "def pairwise_matrix_rownorm(M):\n",
    "    \"\"\"\n",
    "    Compute the matrix E where Eij is ||x_i - x_j||**2\n",
    "    \"\"\"\n",
    "    n = M.shape[0]\n",
    "    V = np.zeros([n, n])\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            V[i][j]=np.linalg.norm(M[i]-M[j])**2\n",
    "    V+=V.T\n",
    "    return V\n",
    "def build_initial_graph(Y, m):\n",
    "    # if well understood create the m nearest neighboor directed graph\n",
    "    n = Y.shape[0]\n",
    "    A = np.zeros([n, n])\n",
    "    E = pairwise_matrix_rownorm(Y)\n",
    "    for i in np.arange(0, n):\n",
    "        sorted_index = np.argsort(E[i])\n",
    "        j_sweep = sorted_index[1:m+1]\n",
    "        den = m * E[i][sorted_index[m+1]] - np.sum(E[i][j_sweep]) # renormalization, but why is it like that?\n",
    "        ei = E[i, sorted_index[m+1]]\n",
    "        for j in j_sweep:\n",
    "            A[i,j] = (ei - E[i, j]) / den\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "655ebfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_k_component_graph (S, is_data_matrix = False, k = 1, w0 = \"naive\", lb = 0, ub = 1e4, alpha = 0,\\\n",
    "                                    beta = 1e4, beta_max = 1e6, fix_beta = True, rho = 1e-2, m = 7,\\\n",
    "                                    maxiter = 1e4, abstol = 1e-6, reltol = 1e-4, eigtol = 1e-9,\\\n",
    "                                    record_objective = False, record_weights = False, verbose = True):\n",
    "  \"\"\"\n",
    "  Learn the Laplacian and adjacency matrix corresponding to a k-component graph\n",
    "  Params:\n",
    "    S: Either the original correlation matrix or the raw data matrix\n",
    "    is_data_matrix: bool, if True then the correlations matrix is computed from S\n",
    "    k: number of components of the final graph\n",
    "    m: number of neighbors considered to build the matrix (only useful if is_data_matrix is true)\n",
    "  \"\"\"\n",
    "  if (is_data_matrix or S.shape[0] != S.shape[1]):\n",
    "    A = build_initial_graph(S, m = m)\n",
    "    D = np.diag(.5 * (np.sum(A,axis=1) + np.sum(A,axis=0)))\n",
    "    L = D - .5 * (A + A.T)\n",
    "    S = np.linalg.pinv(L)\n",
    "    is_data_matrix = True\n",
    "  # number of nodes\n",
    "  n = S.shape[0]\n",
    "  # l1-norm penalty factor\n",
    "  H = alpha * (2 *np.eye(n) - np.ones([n, n]))\n",
    "  K = S + H\n",
    "  # find an appropriate inital guess\n",
    "  if (is_data_matrix):\n",
    "    Sinv = L\n",
    "  else:\n",
    "    Sinv = np.linalg.pinv(S)\n",
    "  # if w0 is either \"naive\" or \"qp\", compute it, else return w0\n",
    "  w0 = w_init(w0, Sinv)\n",
    "  # compute quantities on the initial guess\n",
    "  Lw0 = La(w0)\n",
    "  U0 = laplacian_U_update(Lw = Lw0, k = k)\n",
    "  lambda0 = laplacian_lambda_update(lb = lb, ub = ub, beta = beta, U = U0,\\\n",
    "                                     Lw = Lw0, k = k)\n",
    "\n",
    "  beta_seq = [beta]\n",
    "  time_seq = [0]\n",
    "  start_time = time()\n",
    "  for i in tqdm(range(maxiter)):\n",
    "    #test_time = time()\n",
    "    #test_total_time = time()\n",
    "    w = laplacian_w_update(w = w0, Lw = Lw0, U = U0, beta = beta,\\\n",
    "                            lambd = lambda0, K = K, p=S.shape[0])\n",
    "    #test_laplacian_w_update_time= time() - test_time\n",
    "    #test_time = time()\n",
    "    Lw = La(w)\n",
    "    #test_La_time = time() - test_time\n",
    "    #test_time = time()\n",
    "    U = laplacian_U_update(Lw = Lw, k = k)\n",
    "    #test_laplacian_U_update_time = time() - test_time\n",
    "    #test_time = time()\n",
    "    lambd = laplacian_lambda_update(lb = lb, ub = ub, beta = beta, U = U,\\\n",
    "                                      Lw = Lw, k = k)\n",
    "    #test_laplacian_lambda_update_time = time() - test_time\n",
    "    #test_time = time()\n",
    "    # check for convergence\n",
    "    werr = abs(w0 - w)\n",
    "    has_w_converged = (np.all(werr <= .5 * reltol * (w + w0)) or np.all(werr <= abstol))\n",
    "    time_seq.append(time()-start_time)\n",
    "    if not(fix_beta):\n",
    "      eigvals=np.linalg.eigh(Lw)[0]\n",
    "      n_zero_eigenvalues = np.sum(abs(eigvals) < eigtol)\n",
    "      if (k <= n_zero_eigenvalues):\n",
    "        beta = (1 + rho) * beta\n",
    "      elif (k > n_zero_eigenvalues):\n",
    "        beta = beta / (1 + rho)\n",
    "      if (beta > beta_max):\n",
    "        beta = beta_max\n",
    "      beta_seq.append(beta)\n",
    "    if has_w_converged:\n",
    "      break\n",
    "    # update estimates\n",
    "    w0 = w\n",
    "    U0 = U\n",
    "    lambda0 = lambd\n",
    "    Lw0 = Lw\n",
    "    \"\"\"\n",
    "    test_convergence_time = time() - test_time\n",
    "    test_total_time = time() - test_total_time\n",
    "    print('total time', test_total_time)\n",
    "    print('total ratio (1):', (test_laplacian_w_update_time + test_La_time + test_laplacian_U_update_time + test_laplacian_lambda_update_time + test_convergence_time)/test_total_time)\n",
    "    print('laplacian_w_update', test_laplacian_w_update_time/test_total_time*100)\n",
    "    print('La', test_La_time/test_total_time*100)\n",
    "    print('laplacian_U_update', test_laplacian_U_update_time/test_total_time*100)\n",
    "    print('laplacian_lambda_update', test_laplacian_lambda_update_time/test_total_time*100)\n",
    "    print('convergence', test_convergence_time/test_total_time*100)\"\"\"\n",
    "  # compute the adjacency matrix\n",
    "  Aw = Ad(w)\n",
    "  results = {\"Laplacian\" : Lw, \"Adjacency\" : Aw, \"w\" : w, \"lambd\" : lambd, \"U\" : U,\\\n",
    "                 \"elapsed_time\" : time_seq, \"convergence\" : has_w_converged,\\\n",
    "                  \"beta_seq\" : beta_seq}\n",
    "  return results\n",
    "\n",
    "def learn_cospectral_graph(S, lambd, k = 1, is_data_matrix = False, w0 = \"naive\", alpha = 0,\\\n",
    "                                   beta = 1e4, beta_max = 1e6, fix_beta = True, rho = 1e-2, m = 7,\\\n",
    "                                   maxiter = 1e4, abstol = 1e-6, reltol = 1e-4, eigtol = 1e-9,\\\n",
    "                                   record_objective = False, record_weights = False, verbose = True):\n",
    "  if (is_data_matrix or S.shape[0] != S.shape[1]):\n",
    "    A = build_initial_graph(S, m = m)\n",
    "    D = np.diag(.5 * (np.sum(A,axis=1) + np.sum(A,axis=0)))\n",
    "    L = D - .5 * (A + A.T)\n",
    "    S = np.linalg.pinv(L)\n",
    "    is_data_matrix = True\n",
    "  # number of nodes\n",
    "  n = S.shape[0]\n",
    "  # l1-norm penalty factor\n",
    "  H = alpha * (2 * np.eye(n)- np.ones(n, n))\n",
    "  K = S + H\n",
    "  # find an appropriate inital guess\n",
    "  if (is_data_matrix):\n",
    "    Sinv = L\n",
    "  else:\n",
    "    Sinv = np.linalg.pinv(S)\n",
    "  # if w0 is either \"naive\" or \"qp\", compute it, else return w0\n",
    "  w0 = w_init(w0, Sinv)\n",
    "  # compute quantities on the initial guess\n",
    "  Lw0 = La(w0)\n",
    "  U0 = laplacian_U_update(Lw = Lw0, k = k)\n",
    "  beta_seq = [beta]\n",
    "  time_seq = [0]\n",
    "  start_time = time()\n",
    "  for i in np.arange(maxiter):\n",
    "    w = laplacian_w_update(w = w0, Lw = Lw0, U = U0, beta = beta,\\\n",
    "                            lambd = lambd, K = K)\n",
    "    Lw = La(w)\n",
    "    U = laplacian_U_update(Lw = Lw, k = k)\n",
    "    # check for convergence\n",
    "    werr = abs(w0 - w)\n",
    "    has_w_converged = min(werr <= .5 * reltol * (w + w0)) or min(werr <= abstol)\n",
    "    time_seq.append(time() - start_time)\n",
    "    if not(fix_beta):\n",
    "      eigvals = np.linalg.eigh(Lw)[0]\n",
    "      n_zero_eigenvalues = np.sum(abs(eigvals) < eigtol)\n",
    "      if (k <= n_zero_eigenvalues):\n",
    "        beta = (1 + rho) * beta\n",
    "      elif (k > n_zero_eigenvalues):\n",
    "        beta = beta / (1 + rho)\n",
    "      if (beta > beta_max):\n",
    "        beta = beta_max\n",
    "      beta_seq.append(beta)\n",
    "    if (has_w_converged):\n",
    "      break\n",
    "    # update estimates\n",
    "    w0 = w\n",
    "    U0 = U\n",
    "    Lw0 = Lw\n",
    "  # compute the adjacency matrix\n",
    "  Aw = Ad(w)\n",
    "  results = {\"Laplacian\" : Lw, \"Adjacency\" : Aw, \"w\" : w, \"lambd\" : lambd, \"U\" : U,\\\n",
    "                  \"elapsed_time\" : time_seq, \"convergence\" : has_w_converged,\\\n",
    "                  \"beta_seq\" : beta_seq}\n",
    "  return results\n",
    "\n",
    "def learn_bipartite_graph(S, is_data_matrix = False, z = 0, nu = 1e4, alpha = 0.,\n",
    "                                  w0 = \"naive\", m = 7, maxiter = 1e4, abstol = 1e-6, reltol = 1e-4,\n",
    "                                  record_weights = False, verbose = True):\n",
    "  if is_data_matrix or S.shape[0] != S.shape[1]:\n",
    "    A = build_initial_graph(S, m = m)\n",
    "    D =  np.diag(.5 * (np.sum(A,axis=1) + np.sum(A,axis=0)))\n",
    "    L = D - .5 * (A + A.T)\n",
    "    S = np.linalg.pinv(L)\n",
    "    is_data_matrix = True\n",
    "  # number of nodes\n",
    "  n = S.shape[0]\n",
    "  # note now that S is always some sort of similarity matrix\n",
    "  J = np.ones([n,n])/n\n",
    "  # l1-norm penalty factor\n",
    "  H = alpha * (2 * np.eye(n) - np.ones([n, n]))\n",
    "  K = S + H\n",
    "  # compute initial guess\n",
    "  if is_data_matrix:\n",
    "    Sinv = L\n",
    "  else:\n",
    "    Sinv = np.linalg.pinv(S)\n",
    "  # if w0 is either \"naive\" or \"qp\", compute it, else return w0\n",
    "  w0 = w_init(w0, Sinv)\n",
    "  Lips = 1 / np.linalg.eigh(La(w0) + J)[0][0]\n",
    "  # compute quantities on the initial guess\n",
    "  Aw0 = Ad(w0)\n",
    "  V0 = bipartite_V_update(Aw0, z)\n",
    "  psi0 = bipartite_psi_update(V0, Aw0)\n",
    "  Lips_seq = [Lips]\n",
    "  time_seq = [0]\n",
    "  start_time = time()\n",
    "  ll0 = bipartite_likelihood(Lw = La(w0), K = K, J = J)\n",
    "  fun0 = ll0 + bipartite_prior(nu = nu, Aw = Aw0, psi = psi0, V = V0)\n",
    "  fun_seq = [fun0]\n",
    "  ll_seq = [ll0]\n",
    "  for i in np.arange(maxiter):\n",
    "    # we need to make sure that the Lipschitz constant is large enough\n",
    "    # in order to avoid divergence\n",
    "    while 1:\n",
    "      # compute the update for w\n",
    "      w = bipartite_w_update(w = w0, Aw = Aw0, V = V0, nu = nu, psi = psi0,\n",
    "                              K = K, J = J, Lips = Lips)\n",
    "      # compute the objective function at the updated value of w\n",
    "      fun_t=bipartite_obj_fun(Aw = Ad(w), Lw = La(w), V = V0, psi = psi0,\n",
    "                        K = K, J = J, nu = nu)\n",
    "      \"\"\"fun_t = tryCatch({#TODO\n",
    "                   bipartite.obj_fun(Aw = A(w), Lw = L(w), V = V0, psi = psi0,\n",
    "                                     K = K, J = J, nu = nu)\n",
    "                 }, warning = function(warn) return(Inf), error = function(err) return(Inf)\n",
    "               )\"\"\"\n",
    "      # check if the previous value of the objective function is\n",
    "      # smaller than the current one\n",
    "      Lips_seq.append(Lips)\n",
    "      if fun0 < fun_t:\n",
    "        # in case it is in fact larger, then increase Lips and recompute w\n",
    "        Lips = 2 * Lips\n",
    "    else:\n",
    "        # otherwise decrease Lips and get outta here!\n",
    "        Lips = .5 * Lips\n",
    "        if Lips < 1e-12:\n",
    "          Lips = 1e-12\n",
    "        break\n",
    "    Lw = La(w)\n",
    "    Aw = Ad(w)\n",
    "    V = bipartite_V_update(Aw = Aw, z = z)\n",
    "    psi = bipartite_psi_update(V = V, Aw = Aw)\n",
    "    # compute negloglikelihood and objective function values\n",
    "    ll = bipartite_likelihood(Lw = Lw, K = K, J = J)\n",
    "    fun = ll + bipartite_prior(nu = nu, Aw = Aw, psi = psi, V = V)\n",
    "    # save measurements of time and objective functions\n",
    "    time_seq.append(time()- start_time)\n",
    "    ll_seq.append(ll)\n",
    "    fun_seq.append(fun)\n",
    "    # compute the relative error and check the tolerance on the Adjacency\n",
    "    # matrix and on the objective function\n",
    "    # check for convergence\n",
    "    werr = abs(w0 - w)\n",
    "    has_w_converged = (np.all(werr <= .5 * reltol * (w + w0)) or np.all(werr <= abstol))\n",
    "    if (has_w_converged):\n",
    "      break\n",
    "    # update estimates\n",
    "    fun0 = fun\n",
    "    w0 = w\n",
    "    V0 = V\n",
    "    psi0 = psi\n",
    "    Aw0 = Aw\n",
    "  results = {\"Laplacian\" : Lw, \"Adjacency\" : Aw, \"obj_fun\" : fun_seq, \"loglike\" : ll_seq, \"w\" : w,\n",
    "                  \"psi\" : psi, \"V\" : V, \"elapsed_time\" : time_seq, \"Lips\" : Lips,\n",
    "                  \"Lips_seq\" : Lips_seq, \"convergence\" : (i < maxiter), \"nu\" : nu}\n",
    "  return results\n",
    "\n",
    "\n",
    "def learn_bipartite_k_component_graph(S, is_data_matrix = False, z = 0, k = 1,\\\n",
    "                                              w0 = \"naive\", m = 7, alpha = 0., beta = 1e4,\\\n",
    "                                              rho = 1e-2, fix_beta = True, beta_max = 1e6, nu = 1e4,\\\n",
    "                                              lb = 0, ub = 1e4, maxiter = 1e4, abstol = 1e-6,\\\n",
    "                                              reltol = 1e-4, eigtol = 1e-9,\\\n",
    "                                              record_weights = False, record_objective = False, verbose = True):\n",
    "  if is_data_matrix or S.shape[0] != S.shape[1]:\n",
    "    A = build_initial_graph(S, m = m)\n",
    "    D =  np.diag(.5 * (np.sum(A,axis=1) + np.sum(A,axis=0)))\n",
    "    L = D - .5 * (A + A.T)\n",
    "    S = np.linalg.pinv(L)\n",
    "    is_data_matrix = True\n",
    "  # number of nodes\n",
    "  n = S.shape[0]\n",
    "  # note now that S is always some sort of similarity matrix\n",
    "  J = np.ones([n,n])/n\n",
    "  # l1-norm penalty factor\n",
    "  H = alpha * (2 * np.eye(n) - np.ones([n, n]))\n",
    "  K = S + H\n",
    "  # compute initial guess\n",
    "  if is_data_matrix:\n",
    "    Sinv = L\n",
    "  else:\n",
    "    Sinv = np.linalg.pinv(S)\n",
    "  # if w0 is either \"naive\" or \"qp\", compute it, else return w0\n",
    "  w0 = w_init(w0, Sinv)\n",
    "  # compute quantities on the initial guess\n",
    "  Aw0 = Ad(w0)\n",
    "  Lw0 = La(w0)\n",
    "  V0 = joint_V_update(Aw0, z)\n",
    "  psi0 = bipartite_psi_update(V0, Aw0)\n",
    "  U0 = joint_U_update(Lw0, k)\n",
    "  lambda0 = laplacian_lambda_update(lb, ub, beta, U0, Lw0, k)\n",
    "  beta_seq = [beta]\n",
    "  time_seq = [0]\n",
    "  start_time = time()\n",
    "  for i in np.arange(maxiter):\n",
    "    w = joint_w_update(w0, Lw0, Aw0, U0, V0, lambda0, psi0, beta, nu, K)\n",
    "    Lw = La(w)\n",
    "    Aw = Ad(w)\n",
    "    U = joint_U_update(Lw, k)\n",
    "    V = joint_V_update(Aw, z)\n",
    "    lambd = laplacian_lambda_update(lb, ub, beta, U, Lw, k)\n",
    "    psi = bipartite_psi_update(V, Aw)\n",
    "    time_seq.append(time()-start_time)\n",
    "    werr = abs(w0 - w)\n",
    "    has_w_converged = (np.all(werr <= .5 * reltol * (w + w0)) or np.all(werr <= abstol))\n",
    "    time_seq.append(time()-start_time)\n",
    "    eigvals = np.linalg.eigh(Lw)[0]\n",
    "    if not(fix_beta):\n",
    "      n_zero_eigenvalues = sum(abs(eigvals) < eigtol)\n",
    "      if (k < n_zero_eigenvalues):\n",
    "        beta = (1 + rho) * beta\n",
    "      elif (k > n_zero_eigenvalues):\n",
    "        beta = beta / (1 + rho)\n",
    "      if (beta > beta_max):\n",
    "        beta = beta_max\n",
    "      beta_seq.append(beta)\n",
    "    if (has_w_converged):\n",
    "      break\n",
    "    # update estimates\n",
    "    w0 = w\n",
    "    U0 = U\n",
    "    V0 = V\n",
    "    lambda0 = lambd\n",
    "    psi0 = psi\n",
    "    Lw0 = Lw\n",
    "    Aw0 = Aw\n",
    "  results = {\"Laplacian\" : Lw, \"Adjacency\" : Aw, \"w\" : w, \"psi\" : psi,\n",
    "                  \"lambd\" : lambd, \"V\" : V, \"U\" : U, \"elapsed_time\" : time_seq,\n",
    "                  \"beta_seq\" : beta_seq, \"convergence\" : has_w_converged}\n",
    "  return(results)\n",
    "\n",
    "def nb_connected_component(L):\n",
    "    return np.sum(np.linalg.eigh(L)[0]<10**-12)\n",
    "\n",
    "def is_bipartite(A):\n",
    "    n=A.shape[0]\n",
    "    co=[-1]*n\n",
    "    def parc(u):\n",
    "        for v in range(n):\n",
    "            if A[u][v]>0:\n",
    "                if co[v]==-1:\n",
    "                    co[v]=1-co[u]\n",
    "                    if not(parc(v)):\n",
    "                        return False\n",
    "                elif co[v]+co[u]!=1:\n",
    "                    return False\n",
    "        return True\n",
    "    for u in range(n):\n",
    "        if co[u]==-1:\n",
    "            co[u]=0\n",
    "            if not(parc(u)):\n",
    "                return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2a1063b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "dataset = os.path.join(os.getcwd(),'Cora')\n",
    "dataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "dataset= Planetoid(root=dataset, name='Cora')\n",
    "x = dataset[0].x.detach().cpu().numpy()\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc7b6e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████▌                      | 7086/10000 [59:49<24:35,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimization converged!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# n_samples = 100 * n_feats   #(2000)\n",
    "# # compute the laplacian and correlation matrices\n",
    "# lap = np.diag(adj.sum(axis=0)) - adj\n",
    "# theta = np.linalg.pinv(lap)\n",
    "# # generate samples\n",
    "# x = np.random.multivariate_normal(np.zeros(n_feats), theta, size=n_samples).T\n",
    "\n",
    "\n",
    "# # learn the laplacian and adjacency matrices\n",
    "res_denoising = learn_k_component_graph(x.T, k=4, maxiter=10000)\n",
    "if res_denoising['convergence']: print(\"The optimization converged!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "344bd3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj2=res_denoising['Adjacency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a2263b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(X.shape[1], 64)\n",
    "        self.conv2 = GCNConv(64, NO_OF_CLASSES)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    \n",
    "####### NO output layer is written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbafd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
