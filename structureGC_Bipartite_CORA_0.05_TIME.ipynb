{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f80e3a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "3f80e3a6",
    "outputId": "688d4a21-c2c8-4090-8785-ba9fec49eaef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandeep\\AppData\\Local\\Temp\\ipykernel_26416\\273441208.py:10: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install deeprobust\n",
    "# !conda install pytorch torchvision torchaudio -c pytorch\n",
    "import torch\n",
    "# print(torch.__version__)\n",
    "# !pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "# !pip install torch-geometric\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "from networkx.generators.random_graphs import erdos_renyi_graph\n",
    "from networkx.generators.random_graphs import barabasi_albert_graph\n",
    "from networkx.generators.community import stochastic_block_model\n",
    "from networkx.generators.random_graphs import watts_strogatz_graph\n",
    "from networkx.generators.community import random_partition_graph\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c287cb5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "c287cb5c",
    "outputId": "54552bfd-7681-4b66-bce2-74e2c38e399f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandeep\\AppData\\Local\\Temp\\ipykernel_26416\\4057615484.py:25: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Sandeep\\\\Downloads\\\\Subhanu_ RESULTS\\\\FGC\\\\Experiment for Bipartite'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch_geometric\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_dir = \"./data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "\n",
    "from random import sample\n",
    "from networkx.generators.random_graphs import erdos_renyi_graph\n",
    "from networkx.generators.random_graphs import barabasi_albert_graph\n",
    "from networkx.generators.community import stochastic_block_model\n",
    "from networkx.generators.random_graphs import watts_strogatz_graph\n",
    "from networkx.generators.community import random_partition_graph\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "import random\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csgraph\n",
    "from scipy.sparse.linalg import inv\n",
    "\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3669a0f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "3669a0f9",
    "outputId": "213cddc0-551b-4948-a025-9704edf67d7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Sandeep\\\\Downloads\\\\Subhanu_ RESULTS\\\\FGC\\\\Experiment for Bipartite\\\\Cora'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = os.path.join(os.getcwd(),'Cora')\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "067c3d06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "067c3d06",
    "outputId": "9c7402f2-2cfc-46ea-e604-13ef4b07d6ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: Cora\n",
      "num_nodes: 2708\n",
      "num_edges: 10556\n",
      "num_classes: 7\n",
      "num_features: 1433\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "def get_planetoid_dataset(name, normalize_features=False, transform=None, split=\"public\"):\n",
    "    path = osp.join(osp.dirname(osp.realpath(os.getcwd())), '..', 'data', name)\n",
    "    if split == 'complete':\n",
    "        dataset = Planetoid(path, name)\n",
    "        dataset[0].train_mask.fill_(False)\n",
    "        dataset[0].train_mask[:dataset[0].num_nodes - 1000] = 1\n",
    "        dataset[0].val_mask.fill_(False)\n",
    "        dataset[0].val_mask[dataset[0].num_nodes - 1000:dataset[0].num_nodes - 500] = 1\n",
    "        dataset[0].test_mask.fill_(False)\n",
    "        dataset[0].test_mask[dataset[0].num_nodes - 500:] = 1\n",
    "    else:\n",
    "        dataset = Planetoid(path, name, split=split)\n",
    "    if transform is not None and normalize_features:\n",
    "        dataset.transform = T.Compose([T.NormalizeFeatures(), transform])\n",
    "    elif normalize_features:\n",
    "        dataset.transform = T.NormalizeFeatures()\n",
    "    elif transform is not None:\n",
    "        dataset.transform = transform\n",
    "    return dataset\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "#     lst_names = ['Cora', 'CiteSeer', 'PubMed']\n",
    "    lst_names = ['Cora']\n",
    "    for name in lst_names:\n",
    "        dataset = get_planetoid_dataset(name)\n",
    "        print(f\"dataset: {name}\")\n",
    "        print(f\"num_nodes: {dataset[0]['x'].shape[0]}\")\n",
    "        print(f\"num_edges: {dataset[0]['edge_index'].shape[1]}\")\n",
    "        print(f\"num_classes: {dataset.num_classes}\")\n",
    "        print(f\"num_features: {dataset.num_node_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f8577f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7f8577f3",
    "outputId": "de9c336b-dbd9-40ca-e1fa-58107ade7ce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "torch.Size([2708, 1433]) torch.Size([2708, 2708])\n",
      "torch.Size([2708, 1433]) torch.Size([2708, 2708])\n"
     ]
    }
   ],
   "source": [
    "# from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "# # dataset = NELL(root='/nell')\n",
    "k_ = dataset.num_classes\n",
    "\n",
    "# dataset= Planetoid(root=dataset, name='Cora')\n",
    "print(dataset[0])\n",
    "adj = to_dense_adj(dataset[0].edge_index).cuda()\n",
    "adj = adj[0]\n",
    "labels = dataset[0].y\n",
    "labels = labels.numpy()\n",
    "\n",
    "X = dataset[0].x\n",
    "X = X.to_dense()\n",
    "N = X.shape[0]\n",
    "NO_OF_CLASSES =  len(set(np.array(dataset[0].y)))\n",
    "\n",
    "print(X.shape, adj.shape)\n",
    "\n",
    "nn = int(1*N)\n",
    "X = X[:nn,:]\n",
    "adj = adj[:nn,:nn]\n",
    "A = adj[:nn,:nn]\n",
    "AT= torch.transpose(A,0,1)\n",
    "labels = labels[:nn]\n",
    "print(X.shape,adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "475846d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "475846d5",
    "outputId": "c6102e64-ae54-46d6-8f9b-48ba85a81564"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0757b15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0757b15",
    "outputId": "d35c00b4-f747-4b97-c075-b98efcdb77eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 2708])\n"
     ]
    }
   ],
   "source": [
    "def get_laplacian(adj):\n",
    "    b=torch.ones(adj.shape[0]).cuda()\n",
    "    return torch.diag(adj@b)-adj\n",
    "\n",
    "theta = get_laplacian(adj)\n",
    "print(theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36a2d1ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "36a2d1ca",
    "outputId": "47e7d15b-491d-49ad-9dff-fcdb283b16a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.cuda.FloatTensor'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(theta@A).type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cad0c60b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cad0c60b",
    "outputId": "4de3ae5a-7f39-4649-bae9-c437127dc115"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Delete later\n",
    "theta.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "114a42e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "114a42e0",
    "outputId": "62b0a402-9d33-44be-8e7f-20de623be138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 2708\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = torch.Tensor(X).cuda()\n",
    "NO_OF_NODES = X.shape[0]\n",
    "print(NO_OF_CLASSES,NO_OF_NODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ba32732",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ba32732",
    "outputId": "4d8096c2-cca6-41e5-f7f9-ebd3e815a404"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Delete later\n",
    "features.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b33c30e2",
   "metadata": {
    "id": "b33c30e2"
   },
   "outputs": [],
   "source": [
    "def convertScipyToTensor(coo):\n",
    "  try:\n",
    "    coo = coo.tocoo()\n",
    "  except:\n",
    "    coo = coo\n",
    "  values = coo.data\n",
    "  indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "  i = torch.LongTensor(indices)\n",
    "  v = torch.FloatTensor(values)\n",
    "  shape = coo.shape\n",
    "\n",
    "  return torch.sparse.FloatTensor(i, v, torch.Size(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7f9d72b",
   "metadata": {
    "id": "b7f9d72b"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import random\n",
    "from scipy.sparse.linalg import norm\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "p = X.shape[0]\n",
    "k = int(p*0.5)\n",
    "n = X.shape[1]\n",
    "lr = 1e-5\n",
    "thresh = 1e-10\n",
    "\n",
    "from scipy.sparse import random\n",
    "from scipy.stats import rv_continuous\n",
    "class CustomDistribution(rv_continuous):\n",
    "    def _rvs(self,  size=None, random_state=None):\n",
    "        return random_state.standard_normal(size)\n",
    "temp = CustomDistribution(seed=1)\n",
    "temp2 = temp()  # get a frozen version of the distribution\n",
    "C = random(p, k, density=0.25, random_state=1, data_rvs=temp2.rvs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eecc9adb",
   "metadata": {
    "id": "eecc9adb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(X.shape[1], 64)\n",
    "        self.conv2 = GCNConv(64, NO_OF_CLASSES)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    \n",
    "####### NO output layer is written\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c5a519a",
   "metadata": {
    "id": "1c5a519a"
   },
   "outputs": [],
   "source": [
    "def get_accu(C_0,L,X_t_0):\n",
    "    global labels, NO_OF_CLASSES,k\n",
    "    t=[]\n",
    "    for i in [1]: \n",
    "        C_0_new=np.zeros(C_0.shape)\n",
    "        for i in range(C_0.shape[0]):\n",
    "            C_0_new[i][np.argmax(C_0[i])]=1\n",
    "        # print(C_0_new)\n",
    "        # C_0_new=C_0\n",
    "        from scipy import sparse\n",
    "        #Lc=C_0.T@L@C_0\n",
    "        Lc=C_0_new.T@L@C_0_new\n",
    "        # print(\"L:\", Lc.shape)\n",
    "        # Lc=L_new\n",
    "        #print(Lc)\n",
    "        Wc=(-1*Lc)*(1-np.eye(Lc.shape[0]))\n",
    "        # print(\"W:\", Wc.shape)\n",
    "        Wc[Wc<0.1]=0\n",
    "        Wc=sparse.csr_matrix(Wc)\n",
    "        Wc = Wc.tocoo()\n",
    "        row = torch.from_numpy(Wc.row).to(torch.long)\n",
    "        col = torch.from_numpy(Wc.col).to(torch.long)\n",
    "        edge_index_coarsen2 = torch.stack([row, col], dim=0)\n",
    "        #print(\"edgecoarsen:\", edge_index_coarsen2.shape)\n",
    "        edge_weight = torch.from_numpy(Wc.data)\n",
    "        #print(\"edgeweight:\", edge_weight.shape)\n",
    "        def one_hot(x, class_count):\n",
    "            return torch.eye(class_count)[x, :]\n",
    "\n",
    "        device = torch.device('cpu')\n",
    "#         device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        labels=labels\n",
    "        Y = labels\n",
    "        #print(\"Y:\", Y.shape)\n",
    "        Y = one_hot(Y,NO_OF_CLASSES)\n",
    "        # NO_OF_CLASSES=Y.shape[1]\n",
    "        P=np.linalg.pinv(C_0_new)\n",
    "        labels_coarse = torch.argmax(torch.sparse.mm(torch.Tensor(P).double() , Y.double()).double() , 1)\n",
    "        #print(\"Lables:\", labels_coarse.shape)\n",
    "\n",
    "        #torch.Tensor(C2)@X\n",
    "        Wc=Wc.toarray()\n",
    "        #Wc[Wc<0.01]=0\n",
    "        C2=np.linalg.pinv(C_0_new)\n",
    "#         device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model=Net().to(device)\n",
    "        lr=0.01\n",
    "        decay=0.0001\n",
    "        features_= features.cpu().detach().numpy()\n",
    "        try:\n",
    "          X=np.array(features_.todense())\n",
    "        except:\n",
    "          X = np.array(features_)\n",
    "        #print(\"X:\",X.shape)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=decay)\n",
    "        # criterion=torch.nn.CrossEntropyLoss()\n",
    "        x=sample(range(0, int(k)), k)\n",
    "      \n",
    "        from datetime import datetime\n",
    "        Xt=P@X\n",
    "        # Xt=X_t_0\n",
    "        def train():\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            out = model(torch.Tensor(Xt).to(device),edge_index_coarsen2)\n",
    "            loss = F.nll_loss(out[x], labels_coarse[x])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            return loss\n",
    "        now1 = datetime.now()\n",
    "        losses=[]\n",
    "        for epoch in range(100):\n",
    "            loss=train()\n",
    "            losses.append(loss)\n",
    "            if(epoch%100==0):\n",
    "                print(f'Epoch: {epoch:03d},loss: {loss:.4f}')\n",
    "        now2 = datetime.now()        \n",
    "        pred=model(torch.Tensor(Xt).to(device),edge_index_coarsen2).argmax(dim=1)        \n",
    "        def train_accuracy():\n",
    "            model.eval()\n",
    "            correct = (pred[x] == labels_coarse[x]).sum()\n",
    "            acc = int(correct) /len(x)\n",
    "            return acc\n",
    "    \n",
    "        t+=[(now2-now1).total_seconds()]\n",
    "\n",
    "        zz=sample(range(0, int(NO_OF_NODES)), NO_OF_NODES)\n",
    "        adj_ = adj.cpu().detach().numpy()\n",
    "        Wc=sparse.csr_matrix(adj_)\n",
    "        Wc = Wc.tocoo()\n",
    "        row = torch.from_numpy(Wc.row).to(torch.long)\n",
    "        col = torch.from_numpy(Wc.col).to(torch.long)\n",
    "        edge_index_coarsen = torch.stack([row, col], dim=0)\n",
    "        edge_weight = torch.from_numpy(Wc.data)\n",
    "        pred=model(torch.Tensor(X),edge_index_coarsen).argmax(dim=1)\n",
    "        pred=np.array(pred)\n",
    "        correct =(pred[zz]==labels[zz]).sum()\n",
    "        acc = int(correct) /NO_OF_NODES\n",
    "        return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f724733",
   "metadata": {
    "id": "1f724733"
   },
   "outputs": [],
   "source": [
    "def experiment_structure(alpha_param,lambda_param,beta_param,gamma_param,C,theta,X,A):\n",
    "      p = X.shape[0]\n",
    "      k = int(p*0.5)\n",
    "      n = X.shape[1]\n",
    "      ones = csr_matrix(np.ones((k,k)))\n",
    "      ones = convertScipyToTensor(ones).cuda()\n",
    "      ones = ones.to_dense()\n",
    "      \n",
    "      try:\n",
    "        C = convertScipyToTensor(C)\n",
    "        C = C.to_dense()\n",
    "      except:\n",
    "        C=C\n",
    "      try:\n",
    "        theta = convertScipyToTensor(theta)\n",
    "      except:\n",
    "        theta = theta\n",
    "      try:\n",
    "        X = convertScipyToTensor(X)\n",
    "        X = X.to_dense()\n",
    "      except:\n",
    "        X = X\n",
    "      if(torch.cuda.is_available()):\n",
    "        print(\"GPU is available\")\n",
    "        C = C.cuda()\n",
    "        theta = theta.cuda()\n",
    "        X = X.cuda()\n",
    "        ones = ones.cuda()\n",
    "      \n",
    "        \n",
    "      def bracket_term2fun(C,CT,theta):\n",
    "          # U  = update_U(C,theta).double()\n",
    "          U = torch.stack(update_U(C, theta)).double()\n",
    "          UT= torch.transpose(U,0,1)\n",
    "          Lw = (CT @theta @C).double()\n",
    "          lb= 1e-5\n",
    "          ub = 1e+4\n",
    "          beta = 0.5 \n",
    "          lambda_ =  laplacian_lambda_update(lb, ub, beta, U, Lw, k_,C)   \n",
    "          lambda_matrix =  torch.diag(lambda_,0).cuda()\n",
    "#           print(\"U size\",U.size())\n",
    "          return U@lambda_matrix@UT\n",
    "        \n",
    "      def update_U(C,theta):\n",
    "            \n",
    "        CT= torch.transpose(C,0,1)\n",
    "        product = CT @ theta @ C\n",
    "        matrix = torch.tensor(product)  \n",
    "        eigenvalues, eigenvectors = torch.linalg.eig(product)\n",
    "\n",
    "        # select non-zero eigenvalues and eigenvectors\n",
    "        non_zero_eigenvalues = []\n",
    "        non_zero_eigenvectors = []\n",
    "        for i in range(matrix.shape[0]):\n",
    "            if matrix[i, i] != 0:\n",
    "                non_zero_eigenvalues.append(eigenvalues[i])\n",
    "                non_zero_eigenvectors.append(eigenvectors[:, i])\n",
    "        U = [torch.tensor(eigenvector) for eigenvector in non_zero_eigenvectors]\n",
    "        return U    \n",
    " \n",
    "\n",
    "      def update_C(C):\n",
    "          CT = torch.transpose(C,0,1)\n",
    "          C.size()\n",
    "          t1 = alpha_param*(C@ones).cuda()\n",
    "          bracket_term1 = (CT@theta@C).cuda()\n",
    "          bracket_term2 = bracket_term2fun(C,CT,theta) \n",
    "          bracket_term = bracket_term1 - bracket_term2   # bracket term (CT*theta*C - U*lambda*UT)\n",
    "          t22 = -2*(theta@C).cuda() \n",
    "#           print(t22.type())\n",
    "          t3 = bracket_term1\n",
    "          t7 = bracket_term2\n",
    "          t6 = (CT@A@C).cuda()\n",
    "          t5 = 2* beta_param*(A@C)\n",
    "          t5 = t5.float()\n",
    "          t4 = (1.0/k)\n",
    "          t44 = t4*((torch.ones(k,k)).double()).cuda()\n",
    "#           print(t3.device)\n",
    "#           print(t44.device)\n",
    "          t8 = (t3 + t44).cuda()\n",
    "          t9 = torch.pinverse(t8)                  #change it\n",
    "          t9 = t9.float()\n",
    "#           print(t9.type())\n",
    "#           print(t9)\n",
    "          t10 = (t22@t9).cuda()\n",
    "          t11 = (t6 - t7).cuda()\n",
    "          t11 = t11.float()\n",
    "          t12 = (t5@t11)\n",
    "          t13 = (t1 + t10 +t12).cuda()\n",
    "        \n",
    "          #t2 = beta_param*(theta@C@bracket_term.float())\n",
    "          grad_fc= t13\n",
    "          C_new=C-gamma_param*grad_fc\n",
    "          C_new[C_new<thresh] = thresh\n",
    "          for i in range(len(C_new)):\n",
    "              C_new[i] = C_new[i]/torch.linalg.norm(C_new[i],1)\n",
    "          return C_new        \n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "      #We set c1 = 10−5 and c2 = 10^4 We observed that the experimental performances of the algorithms \n",
    "       #are not sensitive to different values of c1 and c2 as long as they are reasonably small and large,respectively\n",
    "      # K is the number of smallest eigenvalues of the Laplacian matrix that are being ignored while updating the eigenvalues.\n",
    "      def laplacian_lambda_update(lb, ub, beta, U, Lw, k, C):\n",
    "        q = Lw.size(1) - k\n",
    "        U = U.cuda()\n",
    "        UT= torch.transpose(U,0,1)\n",
    "        UT = UT.type(torch.float64)\n",
    "        UT = UT.cuda()\n",
    "        \n",
    "        CT= torch.transpose(C,0,1)\n",
    "        CT = CT.type(torch.float64)\n",
    "        CT = CT.cuda()\n",
    "        \n",
    "        AC=(A@C).double()\n",
    "        AC = AC.cuda()\n",
    "        \n",
    "        Af=(CT@AC).double()\n",
    "        Af = Af.cuda()\n",
    "        Af.device\n",
    "        U.device\n",
    "        dd = U@Af@UT\n",
    "        \n",
    "        product = dd\n",
    "        matrix = torch.tensor(product)            \n",
    "\n",
    "        non_zero_diag_elements = []\n",
    "        for i in range(matrix.shape[0]):\n",
    "            if matrix[i, i] != 0:\n",
    "                non_zero_diag_elements.append(matrix[i, i])\n",
    "            if len(non_zero_diag_elements) == len(matrix):\n",
    "                break\n",
    "\n",
    "        k = len(non_zero_diag_elements)\n",
    "        d = torch.diag(torch.tensor(non_zero_diag_elements))\n",
    "\n",
    "       \n",
    "        lambda_ = 0.5 * (d + torch.sqrt(d.pow(2) + 4 / beta))\n",
    "#         print(lambda_)\n",
    "        lambda_,indices = torch.sort(lambda_, dim=- 1, descending=True)\n",
    "        eps = 1\n",
    "        condition = torch.stack([(lambda_[q] - ub) <= eps,\n",
    "                         (lambda_[0] - lb) >= -eps]).all(dim=0)\n",
    "\n",
    "#                                   (lambda_[1:(q)] - lambda_[0:(q-1)]) >= -eps])\n",
    "        if condition.all():\n",
    "            return lambda_\n",
    "        else:\n",
    "            greater_ub = lambda_ > ub\n",
    "            lesser_lb = lambda_ < lb\n",
    "            lambda_[greater_ub] = ub\n",
    "            lambda_[lesser_lb] = lb\n",
    "            condition = torch.stack([(lambda_[q] - ub) <= eps,\n",
    "                         (lambda_[0] - lb) >= -eps]).all(dim=0)\n",
    "\n",
    "#                                   (lambda_[1:q] - lambda_[0:(q-1)]) >= -eps])\n",
    "            if condition.all():\n",
    "                return lambda_\n",
    "            else:\n",
    "#                 print(lambda_)\n",
    "                raise ValueError(\"eigenvalues are not in increasing order, consider increasing the value of beta\")\n",
    "            \n",
    "\n",
    "      for i in tqdm(range(10)): #update C only 21\n",
    "         C = update_C(C)\n",
    "            \n",
    "      return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "556afd48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "556afd48",
    "outputId": "7f0b9b03-7a98-4a01-ac78-fc754863ff46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\Sandeep\\AppData\\Local\\Temp\\ipykernel_26416\\3238632087.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  matrix = torch.tensor(product)\n",
      "C:\\Users\\Sandeep\\AppData\\Local\\Temp\\ipykernel_26416\\3238632087.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  U = [torch.tensor(eigenvector) for eigenvector in non_zero_eigenvectors]\n",
      "C:\\Users\\Sandeep\\AppData\\Local\\Temp\\ipykernel_26416\\3238632087.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  matrix = torch.tensor(product)\n",
      "100%|██████████| 10/10 [03:03<00:00, 18.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9470\n",
      "Accuracy = 0.8334564254062038 10 0.1 0.1\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:53<00:00, 17.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9442\n",
      "Average accuracy = 82.68094534711965 +/- 0.6646971935007351\n",
      "Params =  10 0.1 0.1\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:14<00:00,  7.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9372\n",
      "Accuracy = 0.8814623338257016 10 0.1 0.01\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:00<00:00, 12.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9384\n",
      "Accuracy = 0.8855243722304283 10 0.1 0.01\n",
      "Average accuracy = 88.3493353028065 +/- 0.2031019202363371\n",
      "Params =  10 0.1 0.01\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:23<00:00,  8.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9410\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:25<00:00,  8.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9466\n",
      "Average accuracy = 87.48153618906942 +/- 0.18463810930576252\n",
      "Params =  10 0.1 0.001\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:51<00:00, 17.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 49531699200.0000\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:45<00:00, 16.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9458\n",
      "Average accuracy = 30.963810930576074 +/- 1.0524372230428374\n",
      "Params =  10 0.1 1\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:25<00:00, 14.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9487\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:23<00:00, 14.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 25276387328.0000\n",
      "Average accuracy = 56.90546528803545 +/- 26.36632200886263\n",
      "Params =  10 0.01 0.1\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:02<00:00,  6.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9541\n",
      "Accuracy = 0.8951255539143279 10 0.01 0.01\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:34<00:00,  9.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9420\n",
      "Accuracy = 0.8977104874446086 10 0.01 0.01\n",
      "Average accuracy = 89.64180206794683 +/- 0.1292466765140332\n",
      "Params =  10 0.01 0.01\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:32<00:00,  9.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9544\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:41<00:00, 10.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9430\n",
      "Average accuracy = 86.39217134416543 +/- 0.24002954209748628\n",
      "Params =  10 0.01 0.001\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:51<00:00, 17.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9466\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:30<00:00, 15.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9468\n",
      "Average accuracy = 63.55243722304284 +/- 2.031019202363371\n",
      "Params =  10 0.01 1\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:33<00:00, 15.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9493\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:37<00:00,  9.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9457\n",
      "Average accuracy = 80.98227474150666 +/- 0.036927621861154725\n",
      "Params =  10 0.001 0.1\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:23<00:00, 14.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9425\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:15<00:00, 13.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9505\n",
      "Average accuracy = 87.83234859675038 +/- 0.49852289512555825\n",
      "Params =  10 0.001 0.01\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:32<00:00,  9.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9476\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:38<00:00,  9.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9483\n",
      "Average accuracy = 86.15214180206794 +/- 0.11078286558345862\n",
      "Params =  10 0.001 0.001\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:22<00:00, 14.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9458\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:17<00:00, 13.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9464\n",
      "Average accuracy = 39.309453471196456 +/- 6.406942392909897\n",
      "Params =  10 0.001 1\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:30<00:00,  9.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9462\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:15<00:00,  7.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 18719709184.0000\n",
      "Average accuracy = 28.323485967503693 +/- 16.395864106351553\n",
      "Params =  10 1 0.1\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:40<00:00, 10.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9474\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:43<00:00, 16.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9463\n",
      "Average accuracy = 46.49187592319055 +/- 6.351550960118171\n",
      "Params =  10 1 0.01\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:12<00:00, 13.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9406\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:57<00:00, 11.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9501\n",
      "Average accuracy = 86.20753323485968 +/- 0.6093057607090113\n",
      "Params =  10 1 0.001\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:39<00:00, 15.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9461\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:47<00:00, 16.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9463\n",
      "Average accuracy = 42.596011816838995 +/- 6.074593796159528\n",
      "Params =  10 1 1\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:43<00:00, 16.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9458\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:37<00:00, 15.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9462\n",
      "Average accuracy = 55.98227474150664 +/- 4.689807976366323\n",
      "Params =  100 0.1 0.1\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:17<00:00, 13.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9451\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:51<00:00, 17.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9448\n",
      "Average accuracy = 60.062776957163955 +/- 5.446824224519942\n",
      "Params =  100 0.1 0.01\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:41<00:00, 16.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9464\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:27<00:00,  8.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9499\n",
      "Average accuracy = 84.4165435745938 +/- 0.4800590841949781\n",
      "Params =  100 0.1 0.001\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:13<00:00,  7.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9466\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:43<00:00, 10.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000,loss: 1.9455\n",
      "Average accuracy = 57.01624815361891 +/- 12.223042836041357\n",
      "Params =  100 0.1 1\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:33<00:40, 13.40s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sandeep\\Downloads\\Subhanu_ RESULTS\\FGC\\Experiment for Bipartite\\structureGC_Bipartite_CORA_0.05_TIME.ipynb Cell 17\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m theta \u001b[39m=\u001b[39m theta\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m a \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m C_0 \u001b[39m=\u001b[39m experiment_structure(alpha_param,lambda_param,beta_param,gamma_param,C,theta,X,A)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m b \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m C_0 \u001b[39m=\u001b[39m C_0\u001b[39m.\u001b[39mcuda()\n",
      "\u001b[1;32mc:\\Users\\Sandeep\\Downloads\\Subhanu_ RESULTS\\FGC\\Experiment for Bipartite\\structureGC_Bipartite_CORA_0.05_TIME.ipynb Cell 17\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=164'>165</a>\u001b[0m           \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39meigenvalues are not in increasing order, consider increasing the value of beta\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=167'>168</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m)): \u001b[39m#update C only 21\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=168'>169</a>\u001b[0m    C \u001b[39m=\u001b[39m update_C(C)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=170'>171</a>\u001b[0m \u001b[39mreturn\u001b[39;00m C\n",
      "\u001b[1;32mc:\\Users\\Sandeep\\Downloads\\Subhanu_ RESULTS\\FGC\\Experiment for Bipartite\\structureGC_Bipartite_CORA_0.05_TIME.ipynb Cell 17\u001b[0m in \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m t1 \u001b[39m=\u001b[39m alpha_param\u001b[39m*\u001b[39m(C\u001b[39m@ones\u001b[39m)\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m bracket_term1 \u001b[39m=\u001b[39m (CT\u001b[39m@theta\u001b[39m\u001b[39m@C\u001b[39m)\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m bracket_term2 \u001b[39m=\u001b[39m bracket_term2fun(C,CT,theta) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m bracket_term \u001b[39m=\u001b[39m bracket_term1 \u001b[39m-\u001b[39m bracket_term2   \u001b[39m# bracket term (CT*theta*C - U*lambda*UT)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m t22 \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m(theta\u001b[39m@C\u001b[39m)\u001b[39m.\u001b[39mcuda() \n",
      "\u001b[1;32mc:\\Users\\Sandeep\\Downloads\\Subhanu_ RESULTS\\FGC\\Experiment for Bipartite\\structureGC_Bipartite_CORA_0.05_TIME.ipynb Cell 17\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbracket_term2fun\u001b[39m(C,CT,theta):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m# U  = update_U(C,theta).double()\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     U \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(update_U(C, theta))\u001b[39m.\u001b[39mdouble()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     UT\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtranspose(U,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     Lw \u001b[39m=\u001b[39m (CT \u001b[39m@theta\u001b[39m \u001b[39m@C\u001b[39m)\u001b[39m.\u001b[39mdouble()\n",
      "\u001b[1;32mc:\\Users\\Sandeep\\Downloads\\Subhanu_ RESULTS\\FGC\\Experiment for Bipartite\\structureGC_Bipartite_CORA_0.05_TIME.ipynb Cell 17\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m product \u001b[39m=\u001b[39m CT \u001b[39m@\u001b[39m theta \u001b[39m@\u001b[39m C\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m matrix \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(product)  \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m eigenvalues, eigenvectors \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49meig(product)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# select non-zero eigenvalues and eigenvectors\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sandeep/Downloads/Subhanu_%20RESULTS/FGC/Experiment%20for%20Bipartite/structureGC_Bipartite_CORA_0.05_TIME.ipynb#X22sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m non_zero_eigenvalues \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "        # sns.heatmap(C_0.T@C_0)\n",
    "import time   \n",
    "        \n",
    "highest_accuracy=0\n",
    "lambda_param = 0.001\n",
    "#0.0001,0.0001,10,0.0001\n",
    "for alpha_param in [10,100,0.1,1]:\n",
    "  for beta_param in [0.1,0.01,0.001,1]:\n",
    "      for gamma_param in [0.1,0.01,0.001,1]:\n",
    "            \n",
    "        av = []\n",
    "        for _ in range(2):\n",
    "            avg_accuracy_all=[]\n",
    "            X=X.cuda()\n",
    "            for _ in range(1):\n",
    "              C = random(p, k, density=0.15, random_state=1, data_rvs=temp2.rvs)\n",
    "              A = A.cuda()\n",
    "              theta = theta.cuda()\n",
    "              a = time.time()\n",
    "              C_0 = experiment_structure(alpha_param,lambda_param,beta_param,gamma_param,C,theta,X,A)\n",
    "              b = time.time()\n",
    "              C_0 = C_0.cuda()\n",
    "              L = theta\n",
    "              L=L.cuda()\n",
    "              pseudo_C = torch.linalg.pinv(C_0)\n",
    "              X_t_0 = pseudo_C@X\n",
    "              C_test = C_0.cpu().detach().numpy()\n",
    "              X_t_test = X_t_0.cpu().detach().numpy()\n",
    "              L_test = L.cpu().detach().numpy() \n",
    "              c = time.time()\n",
    "              acc = get_accu(C_test,L_test,X_t_test)\n",
    "              d = time.time()\n",
    "              # print(\"Time taken:\", b-a+d-c)\n",
    "              av.append(acc)\n",
    "              if highest_accuracy<acc:\n",
    "                highest_accuracy=acc\n",
    "                print(\"Accuracy = \" + str(acc) + \" \" + str(alpha_param)+\" \" + str(beta_param)+\" \"+str(gamma_param))\n",
    "        print(\"Average accuracy = \" + str(np.mean(av)*100)  + \" +/- \" + str(np.std(av)*100))\n",
    "        print(\"Params =  \" + str(alpha_param)+\" \" + str(beta_param)+\" \"+str(gamma_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "pqDLVv1Wn9RD",
   "metadata": {
    "id": "pqDLVv1Wn9RD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8977104874446086"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FN7Cp3UQoMKv",
   "metadata": {
    "id": "FN7Cp3UQoMKv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
