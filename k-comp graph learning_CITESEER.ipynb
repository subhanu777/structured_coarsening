{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53a1e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as skd\n",
    "import sklearn.metrics as skm\n",
    "from time import *\n",
    "from tqdm import tqdm\n",
    "def A_to_L(A):\n",
    "    D=np.diag(np.sum(A,axis=0))\n",
    "    return D-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf29680f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#First, we use the spectralGraphTopology to denoise laplacian matrices polluted with noise. \n",
    "# We generate a 4 components adjacency matrix\n",
    "\n",
    "\n",
    "\n",
    "n_class_feats = 5\n",
    "n_classes = 4\n",
    "n_feats = n_classes * n_class_feats\n",
    "prob_intra = 1\n",
    "prob_extra = 0.3\n",
    "max_weight_intra = 1\n",
    "max_weight_extra = 0.3\n",
    "adj = np.zeros((n_feats, n_feats))\n",
    "for i in range(n_classes):\n",
    "    i_start = i * n_class_feats\n",
    "    i_end = i_start + n_class_feats\n",
    "    for ii in range(i_start, i_end):\n",
    "        for jj in range(ii+1, i_end):\n",
    "            adj[ii, jj] = np.random.binomial(n=1, p=prob_intra) * np.random.uniform(high=max_weight_intra)\n",
    "plt.matshow(adj+adj.T)\n",
    "plt.title(\"Original matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b044de2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(n_feats):\n",
    "    for j in range(i+1, n_feats):\n",
    "        adj[i, j] += np.random.binomial(n=1, p=prob_extra) * np.random.uniform(high=max_weight_extra)\n",
    "adj = adj + adj.T\n",
    "plt.matshow(adj)\n",
    "plt.title(\"Noisy matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5518072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helpers\n",
    "import numpy as np\n",
    "from sklearn.isotonic import *\n",
    "from numba import njit\n",
    "\n",
    "# Computes the Adjacency linear operator which maps a vector of weights into\n",
    "# a valid Adjacency matrix.\n",
    "# @param w weight vector of the graph\n",
    "# @return Aw the Adjacency matrix\n",
    "def Ad(v):#TODO check new version still works\n",
    "    \"\"\"take an p(p-1)//2 array and return the adjacency matrice\"\"\"\n",
    "    p=1\n",
    "    while (p*(p-1))//2!=v.shape[0]:\n",
    "        p+=1\n",
    "    a = np.zeros([p,p])\n",
    "    s=0\n",
    "    for nb in range(p-1,0,-1):\n",
    "        i=p-1-nb\n",
    "        a[i][i+1:]=v[s:s+p-i-1]\n",
    "        \"\"\"for j in range(i+1,p):\n",
    "            a[i][j] = v[s+j-i-1]\n",
    "            a[j][i] = v[s+j-i-1]\"\"\"\n",
    "        s += nb\n",
    "    a+=a.T\n",
    "    return a\n",
    "\n",
    "# Computes the Laplacian linear operator which maps a vector of weights into a valid Laplacian matrix.\n",
    "# @param w weight vector of the graph\n",
    "# @return Lw the Laplacian matrix\n",
    "def La(v):\n",
    "    a = -Ad(v)\n",
    "    for k in range(a.shape[0]):\n",
    "        a[k][k]=-np.sum(a[k])\n",
    "    return a\n",
    "\n",
    "@njit\n",
    "def Lstar(M):\n",
    "  \"\"\"\n",
    "  Compute the adjoint operator of L\n",
    "  \"\"\"\n",
    "  N = M.shape[1]\n",
    "  k = (N * (N - 1)) // 2\n",
    "  j, l = 0, 1\n",
    "  w = np.zeros(k)\n",
    "  for i in np.arange(k):\n",
    "    w[i] = M[j, j] + M[l, l] - (M[l, j] + M[j, l])\n",
    "    if (l == (N - 1)):\n",
    "        j += 1\n",
    "        l = j + 1\n",
    "    else:\n",
    "      l += 1\n",
    "  return w\n",
    "\n",
    "#Computes the matrix form of the composition of the operators Lstar and\n",
    "# L, i.e., Lstar o L.\n",
    "#\n",
    "# @param n number of columns/rows\n",
    "# @return M the composition of Lstar and L\n",
    "def Mmat(n):\n",
    "  e = np.zeros(n)\n",
    "  M = np.zeros([n, n])\n",
    "  e[0] = 1\n",
    "  M[0] = Lstar(La(e))\n",
    "  for j in np.arange(1,n):\n",
    "    e[j - 1] = 0\n",
    "    e[j] = 1\n",
    "    M[j] = Lstar(L(e))\n",
    "  return M.T\n",
    "\n",
    "@njit\n",
    "def Astar(M):\n",
    "  N = M.shape[1]\n",
    "  k = (N * (N - 1))//2\n",
    "  j = 0\n",
    "  l = 1\n",
    "  w=np.zeros(k)\n",
    "\n",
    "  for i in np.arange(k):\n",
    "    w[i] = M[l, j] + M[j, l]\n",
    "    if l == (N - 1):\n",
    "      j+=1\n",
    "      l = j+1\n",
    "    else:\n",
    "      l+=1\n",
    "  return w\n",
    "\n",
    "\n",
    "# Computes the matrix form of the composition of the operators Astar and\n",
    "# A, i.e., Astar o A.\n",
    "def Pmat(n):\n",
    "  e = np.zeros(n)\n",
    "  M = np.zeros([n, n])\n",
    "  e[0] = 1;\n",
    "  M[0] = Astar(Ad(e))\n",
    "  for j in np.arange(1,n):\n",
    "    e[j - 1] = 0\n",
    "    e[j] = 1\n",
    "    M[j] = Astar(A(e))\n",
    "  return M.T\n",
    "\n",
    "def vec(M):\n",
    "  return M.T.flatten()\n",
    "\n",
    "def vecLmat(n):\n",
    "  ncols = (n * (n - 1))//2\n",
    "  nrows = n * n\n",
    "\n",
    "  e = np.zeros(ncols)\n",
    "  R = np.zeros([nrows,ncols])\n",
    "  e[0] = 1;\n",
    "  R[0] = vec(L(e));\n",
    "  for j in np.arange(1,ncols):\n",
    "    e[j - 1] = 0;\n",
    "    e[j] = 1;\n",
    "    R[j] = vec(L(e));\n",
    "  return R.T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Computes the inverse of the L operator.\n",
    "\n",
    "# @param M Laplacian matrix\n",
    "# @return w the weight vector of the graph\n",
    "def Linv(M):\n",
    "  n = M.shape[0]\n",
    "  return np.concatenate([-M[i][i+1:] for i in np.arange(n)])\n",
    "\n",
    "#get the n(n-1)//2 vector from the laplacian(or A?)\n",
    "#M is laplacian\n",
    "#w is weight vector\n",
    "def Ainv(M):\n",
    "  n = M.shape[0]\n",
    "  return np.concatenate([M[i][i+1:] for i in np.arange(n)])\n",
    "\n",
    "\n",
    "def isoreg(y):\n",
    "    \"\"\"\n",
    "    Compute the isotonic regression of a vector y\n",
    "    For compatibity reasons, we chosse an arbitrary x as training data\n",
    "    but x is useless as we only keep the estimates of the y_i and never interpolate\n",
    "    \"\"\"\n",
    "    x = np.arange(len(y))\n",
    "    isoreg = IsotonicRegression()\n",
    "    isoreg.fit(x, y)\n",
    "    return isoreg.f_(x)\n",
    "\n",
    "\n",
    "\n",
    "def w_init(w0, Sinv):\n",
    "  \"\"\"\n",
    "  Initialize w0, the vectorized upper triangular coefficients of the adjacency matrix\n",
    "  \"\"\"\n",
    "  if type(w0) is str:\n",
    "    if (w0 == \"qp\"):\n",
    "      R = vecLmat(Sinv.shape[1])\n",
    "      qp = 0\n",
    "      assert False,\"idk\"\n",
    "      #quadprog::solve.QP(crossprod(R), t(R) %*% vec(Sinv), diag(ncol(R)))\n",
    "      w0 = qp#qp$solution\n",
    "    elif (w0 == \"naive\"):\n",
    "      w0 = Linv(Sinv)\n",
    "      w0[w0 < 0] = 0 # Should not happen\n",
    "  return w0\n",
    "\n",
    "\n",
    "\n",
    "def laplacian_w_update(w, Lw, U, beta, lambd, K, p):\n",
    "  \"\"\"\n",
    "  Update w according to equation 38\n",
    "  \"\"\"\n",
    "  t = lambd[:, None]**0.5 * U.T\n",
    "  c = Lstar(t.T@t - K / beta)\n",
    "  grad_f = Lstar(Lw) - c\n",
    "  if 1:\n",
    "    M_grad_f = - Lstar(La(grad_f))\n",
    "    wT_M_grad_f = np.sum(w * M_grad_f)\n",
    "    dwT_M_dw = np.sum(grad_f * M_grad_f)\n",
    "  # exact line search\n",
    "    t = (wT_M_grad_f - np.sum(c * grad_f)) / dwT_M_dw\n",
    "  else:\n",
    "      t=1/(2*p)\n",
    "  w_update = w - t * grad_f\n",
    "  w_update[w_update < 0] = 0\n",
    "  return w_update\n",
    "\n",
    "\n",
    "\n",
    "def joint_w_update(w, Lw, Aw, U, V, lambd, psi, beta, nu, K):\n",
    "  t=lambd[:, None]**0.5*U.T\n",
    "  ULmdUT = t.T@t\n",
    "  VPsiVT = V @ np.diag(psi) @ V.T\n",
    "  c1 = Lstar(beta * ULmdUT - K)\n",
    "  c2 = nu * Astar(VPsiVT)\n",
    "  Mw = Lstar(Lw)\n",
    "  Pw = 2 * w\n",
    "  grad_f1 = beta * Mw - c1\n",
    "  M_grad_f1 = Lstar(La(grad_f1))\n",
    "  grad_f2 = nu * Pw - c2\n",
    "  P_grad_f2 = 2 * grad_f2\n",
    "  grad_f = grad_f1 + grad_f2\n",
    "  t = np.sum((beta * Mw + nu * Pw - (c1 + c2)) * grad_f) / np.sum(grad_f * (beta * M_grad_f1 + nu * P_grad_f2))\n",
    "  w_update = w - t * (grad_f1 + grad_f2)\n",
    "  w_update[w_update < 0] = 0\n",
    "  return w_update\n",
    "\n",
    "\n",
    "def bipartite_w_update(w, Aw, V, nu, psi, K, J, Lips):\n",
    "  reg_eps = 0\n",
    "  grad_h = 2 * w - Astar(V @ np.diag(psi) @ V.T) #+ Lstar(K) / beta#\n",
    "  w_update = w - (Lstar(np.linalg.inv(La(w) + J+np.eye(J.shape[0])*reg_eps) + K) + nu * grad_h) / (2 * nu + Lips)\n",
    "  w_update[w_update < 0] = 0#TODO faire en sorte que la régularisation ligne précédent ne soit pas nécessaire\n",
    "  return w_update\n",
    "\n",
    "\n",
    "\n",
    "def laplacian_U_update(Lw, k):\n",
    "  \"\"\"\n",
    "  Return all but the k first eigenvectors of the Laplacian Lw\n",
    "  \"\"\"\n",
    "  return np.linalg.eigh(Lw)[1][:, k:]\n",
    "\n",
    "\n",
    "def bipartite_V_update(Aw, z):\n",
    "  n = Aw.shape[1]\n",
    "  V = np.linalg.eigh(Aw)[1]\n",
    "  return np.concatenate([V[:, :(n - z)//2], V[:,(n + z)//2:n]],axis=1)\n",
    "\n",
    "\n",
    "def joint_U_update(Lw,k):\n",
    "  return np.linalg.eigh(Lw)[1][:, k:]\n",
    "\n",
    "\n",
    "def joint_V_update(Aw,z):\n",
    "  return bipartite_V_update(Aw,z)\n",
    "\n",
    "\n",
    "\n",
    "def laplacian_lambda_update(lb, ub, beta, U, Lw, k):\n",
    "  \"\"\"\n",
    "  Update lambda according to algorithm 1\n",
    "  \"\"\"\n",
    "  q = Lw.shape[1] - k\n",
    "  d = np.diagonal(U.T @ Lw @ U)\n",
    "  # unconstrained solution as initial point\n",
    "  lambd = .5 * (d + (d**2 + 4 / beta)**0.5)\n",
    "  eps = 1e-9\n",
    "  condition_ub = np.array([(lambd[q-1] - ub) <= eps])\n",
    "  condition_lb = np.array([(lambd[0] - lb) >= -eps])\n",
    "  condition_ordered = (lambd[1:q] - lambd[0:(q-1)]) >= -eps\n",
    "  condition = np.concatenate([condition_ub,\\\n",
    "                 condition_lb,\\\n",
    "                 condition_ordered])\n",
    "  if np.all(condition):\n",
    "    return lambd\n",
    "  else:\n",
    "    greater_ub = lambd > ub\n",
    "    lesser_lb = lambd < lb\n",
    "    lambd[greater_ub] = ub\n",
    "    lambd[lesser_lb] = lb\n",
    "  condition_ub = np.array([(lambd[q-1] - ub) <= eps])\n",
    "  condition_lb = np.array([(lambd[0] - lb) >= -eps])\n",
    "  condition_ordered = (lambd[1:q] - lambd[:(q-1)]) >= -eps\n",
    "  condition = np.concatenate([condition_ub,\\\n",
    "                 condition_lb,\\\n",
    "                 condition_ordered])\n",
    "  if np.all(condition):\n",
    "    return (lambd)\n",
    "  else:\n",
    "    print(lambd)\n",
    "    raise ValueError('eigenvalues are not in increasing order consider increasing the value of beta')\n",
    "\n",
    "\n",
    "def bipartite_psi_update(V, Aw, lb = -np.inf, ub = np.inf):\n",
    "  c = np.diagonal(V.T @ Aw @ V)\n",
    "  n = c.shape[0]\n",
    "  c_tilde = .5 * (c[(n//2):][::-1] - c[:(n//2)])\n",
    "  x = isoreg(c_tilde[::-1])\n",
    "  #x <- stats::isoreg(rev(c_tilde))$yf # R\n",
    "  x = np.concatenate((-x[::-1], x))\n",
    "  #x <- c(-rev(x), x) # R\n",
    "  x[x < lb] = lb\n",
    "  x[x > ub] = ub\n",
    "  return x\n",
    "\n",
    "\n",
    "def Ad(v):#TODO check new version still works\n",
    "    \"\"\"take an p(p-1)//2 array and return the adjacency matrice\"\"\"\n",
    "    p=1\n",
    "    while (p*(p-1))//2!=v.shape[0]:\n",
    "        p+=1\n",
    "    a = np.zeros([p,p])\n",
    "    s=0\n",
    "    for nb in range(p-1,0,-1):\n",
    "        i=p-1-nb\n",
    "        a[i][i+1:]=v[s:s+p-i-1]\n",
    "        \"\"\"for j in range(i+1,p):\n",
    "            a[i][j] = v[s+j-i-1]\n",
    "            a[j][i] = v[s+j-i-1]\"\"\"\n",
    "        s += nb\n",
    "    a+=a.T\n",
    "    return a\n",
    "\n",
    "\n",
    "def La(v):\n",
    "    a = -Ad(v)\n",
    "    for k in range(a.shape[0]):\n",
    "        a[k][k]=-np.sum(a[k])\n",
    "    return a\n",
    "\n",
    "\n",
    "def Linv(M):\n",
    "  n = M.shape[0]\n",
    "  return np.concatenate([-M[i][i+1:] for i in np.arange(n)])\n",
    "\n",
    "#get the n(n-1)//2 vector from the laplacian(or A?)\n",
    "#M is laplacian\n",
    "#w is weight vector\n",
    "def Ainv(M):\n",
    "  n = M.shape[0]\n",
    "  return np.concatenate([M[i][i+1:] for i in np.arange(n)])\n",
    "\n",
    "\n",
    "\n",
    "def w_init(w0, Sinv):\n",
    "  \"\"\"\n",
    "  Initialize w0, the vectorized upper triangular coefficients of the adjacency matrix\n",
    "  \"\"\"\n",
    "  if type(w0) is str:\n",
    "    if (w0 == \"qp\"):\n",
    "      R = vecLmat(Sinv.shape[1])\n",
    "      qp = 0\n",
    "      assert False,\"idk\"\n",
    "      #quadprog::solve.QP(crossprod(R), t(R) %*% vec(Sinv), diag(ncol(R)))\n",
    "      w0 = qp#qp$solution\n",
    "    elif (w0 == \"naive\"):\n",
    "      w0 = Linv(Sinv)\n",
    "      w0[w0 < 0] = 0 # Should not happen\n",
    "  return w0\n",
    "\n",
    "\n",
    "def pairwise_matrix_rownorm(M):\n",
    "    \"\"\"\n",
    "    Compute the matrix E where Eij is ||x_i - x_j||**2\n",
    "    \"\"\"\n",
    "    n = M.shape[0]\n",
    "    V = np.zeros([n, n])\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            V[i][j]=np.linalg.norm(M[i]-M[j])**2\n",
    "    V+=V.T\n",
    "    return V\n",
    "# def build_initial_graph(Y, m):\n",
    "#     # if well understood create the m nearest neighboor directed graph\n",
    "#     n = Y.shape[0]\n",
    "#     A = np.zeros([n, n])\n",
    "#     E = pairwise_matrix_rownorm(Y)\n",
    "#     for i in np.arange(0, n):\n",
    "#         sorted_index = np.argsort(E[i])\n",
    "#         j_sweep = sorted_index[1:m+1]\n",
    "#         den = m * E[i][sorted_index[m+1]] - np.sum(E[i][j_sweep]) # renormalization, but why is it like that?\n",
    "#         ei = E[i, sorted_index[m+1]]\n",
    "#         for j in j_sweep:\n",
    "#             A[i,j] = (ei - E[i, j]) / den\n",
    "#     return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "655ebfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_k_component_graph (adj,L, S, is_data_matrix = False, k=4 , w0 = \"naive\", lb = 0, ub = 1e4, alpha = 0,\\\n",
    "                                    beta = 1e4, beta_max = 1e6, fix_beta = True, rho = 1e-2, m = 7,\\\n",
    "                                    maxiter = 1e4, abstol = 1e-6, reltol = 1e-4, eigtol = 1e-9,\\\n",
    "                                    record_objective = False, record_weights = False, verbose = True):\n",
    "  \"\"\"\n",
    "  Learn the Laplacian and adjacency matrix corresponding to a k-component graph\n",
    "  Params:\n",
    "    S: Either the original correlation matrix or the raw data matrix\n",
    "    is_data_matrix: bool, if True then the correlations matrix is computed from S\n",
    "    k: number of components of the final graph\n",
    "    m: number of neighbors considered to build the matrix (only useful if is_data_matrix is true)\n",
    "  \"\"\"\n",
    "  if (is_data_matrix or S.shape[0] != S.shape[1]):\n",
    "    A = adj\n",
    "    # D = np.diag(.5 * (np.sum(A,axis=1) + np.sum(A,axis=0)))\n",
    "    # L = D - .5 * (A + A.T)\n",
    "    S = np.linalg.pinv(L)\n",
    "    is_data_matrix = True\n",
    "  # number of nodes\n",
    "  n = S.shape[0]\n",
    "  # l1-norm penalty factor\n",
    "  H = alpha * (2 *np.eye(n) - np.ones([n, n]))\n",
    "  K = S + H\n",
    "  # find an appropriate inital guess\n",
    "  if (is_data_matrix):\n",
    "    Sinv = L\n",
    "  else:\n",
    "    Sinv = np.linalg.pinv(S)\n",
    "  # if w0 is either \"naive\" or \"qp\", compute it, else return w0\n",
    "  w0 = w_init(w0, Sinv)\n",
    "  # compute quantities on the initial guess\n",
    "  Lw0 = La(w0)\n",
    "  U0 = laplacian_U_update(Lw = Lw0, k = k)\n",
    "  lambda0 = laplacian_lambda_update(lb = lb, ub = ub, beta = beta, U = U0,\\\n",
    "                                     Lw = Lw0, k = k)\n",
    "\n",
    "  beta_seq = [beta]\n",
    "  time_seq = [0]\n",
    "  # start_time = time()\n",
    "  for i in tqdm(range(maxiter)):\n",
    "    #test_time = time()\n",
    "    #test_total_time = time()\n",
    "    w = laplacian_w_update(w = w0, Lw = Lw0, U = U0, beta = beta,\\\n",
    "                            lambd = lambda0, K = K, p=S.shape[0])\n",
    "    #test_laplacian_w_update_time= time() - test_time\n",
    "    #test_time = time()\n",
    "    Lw = La(w)\n",
    "    #test_La_time = time() - test_time\n",
    "    #test_time = time()\n",
    "    U = laplacian_U_update(Lw = Lw, k = k)\n",
    "    #test_laplacian_U_update_time = time() - test_time\n",
    "    #test_time = time()\n",
    "    lambd = laplacian_lambda_update(lb = lb, ub = ub, beta = beta, U = U,\\\n",
    "                                      Lw = Lw, k = k)\n",
    "    #test_laplacian_lambda_update_time = time() - test_time\n",
    "    #test_time = time()\n",
    "    # check for convergence\n",
    "    werr = abs(w0 - w)\n",
    "    has_w_converged = (np.all(werr <= .5 * reltol * (w + w0)) or np.all(werr <= abstol))\n",
    "    # time_seq.append(time()-start_time)\n",
    "    if not(fix_beta):\n",
    "      eigvals=np.linalg.eigh(Lw)[0]\n",
    "      n_zero_eigenvalues = np.sum(abs(eigvals) < eigtol)\n",
    "      if (k <= n_zero_eigenvalues):\n",
    "        beta = (1 + rho) * beta\n",
    "      elif (k > n_zero_eigenvalues):\n",
    "        beta = beta / (1 + rho)\n",
    "      if (beta > beta_max):\n",
    "        beta = beta_max\n",
    "      beta_seq.append(beta)\n",
    "    if has_w_converged:\n",
    "      break\n",
    "    # update estimates\n",
    "    w0 = w\n",
    "    U0 = U\n",
    "    lambda0 = lambd\n",
    "    Lw0 = Lw\n",
    "    \"\"\"\n",
    "    test_convergence_time = time() - test_time\n",
    "    test_total_time = time() - test_total_time\n",
    "    print('total time', test_total_time)\n",
    "    print('total ratio (1):', (test_laplacian_w_update_time + test_La_time + test_laplacian_U_update_time + test_laplacian_lambda_update_time + test_convergence_time)/test_total_time)\n",
    "    print('laplacian_w_update', test_laplacian_w_update_time/test_total_time*100)\n",
    "    print('La', test_La_time/test_total_time*100)\n",
    "    print('laplacian_U_update', test_laplacian_U_update_time/test_total_time*100)\n",
    "    print('laplacian_lambda_update', test_laplacian_lambda_update_time/test_total_time*100)\n",
    "    print('convergence', test_convergence_time/test_total_time*100)\"\"\"\n",
    "  # compute the adjacency matrix\n",
    "  Aw = Ad(w)\n",
    "  results = {\"Laplacian\" : Lw, \"Adjacency\" : Aw, \"w\" : w, \"lambd\" : lambd, \"U\" : U,\\\n",
    "                 \"elapsed_time\" : time_seq, \"convergence\" : has_w_converged,\\\n",
    "                  \"beta_seq\" : beta_seq}\n",
    "  return results\n",
    "\n",
    "def learn_cospectral_graph(S, lambd, k = 1, is_data_matrix = False, w0 = \"naive\", alpha = 0,\\\n",
    "                                   beta = 1e4, beta_max = 1e6, fix_beta = True, rho = 1e-2, m = 7,\\\n",
    "                                   maxiter = 1e4, abstol = 1e-6, reltol = 1e-4, eigtol = 1e-9,\\\n",
    "                                   record_objective = False, record_weights = False, verbose = True):\n",
    "  if (is_data_matrix or S.shape[0] != S.shape[1]):\n",
    "    A = build_initial_graph(S, m = m)\n",
    "    D = np.diag(.5 * (np.sum(A,axis=1) + np.sum(A,axis=0)))\n",
    "    L = D - .5 * (A + A.T)\n",
    "    S = np.linalg.pinv(L)\n",
    "    is_data_matrix = True\n",
    "  # number of nodes\n",
    "  n = S.shape[0]\n",
    "  # l1-norm penalty factor\n",
    "  H = alpha * (2 * np.eye(n)- np.ones(n, n))\n",
    "  K = S + H\n",
    "  # find an appropriate inital guess\n",
    "  if (is_data_matrix):\n",
    "    Sinv = L\n",
    "  else:\n",
    "    Sinv = np.linalg.pinv(S)\n",
    "  # if w0 is either \"naive\" or \"qp\", compute it, else return w0\n",
    "  w0 = w_init(w0, Sinv)\n",
    "  # compute quantities on the initial guess\n",
    "  Lw0 = La(w0)\n",
    "  U0 = laplacian_U_update(Lw = Lw0, k = k)\n",
    "  beta_seq = [beta]\n",
    "  time_seq = [0]\n",
    "  start_time = time()\n",
    "  for i in np.arange(maxiter):\n",
    "    w = laplacian_w_update(w = w0, Lw = Lw0, U = U0, beta = beta,\\\n",
    "                            lambd = lambd, K = K)\n",
    "    Lw = La(w)\n",
    "    U = laplacian_U_update(Lw = Lw, k = k)\n",
    "    # check for convergence\n",
    "    werr = abs(w0 - w)\n",
    "    has_w_converged = min(werr <= .5 * reltol * (w + w0)) or min(werr <= abstol)\n",
    "    time_seq.append(time() - start_time)\n",
    "    if not(fix_beta):\n",
    "      eigvals = np.linalg.eigh(Lw)[0]\n",
    "      n_zero_eigenvalues = np.sum(abs(eigvals) < eigtol)\n",
    "      if (k <= n_zero_eigenvalues):\n",
    "        beta = (1 + rho) * beta\n",
    "      elif (k > n_zero_eigenvalues):\n",
    "        beta = beta / (1 + rho)\n",
    "      if (beta > beta_max):\n",
    "        beta = beta_max\n",
    "      beta_seq.append(beta)\n",
    "    if (has_w_converged):\n",
    "      break\n",
    "    # update estimates\n",
    "    w0 = w\n",
    "    U0 = U\n",
    "    Lw0 = Lw\n",
    "  # compute the adjacency matrix\n",
    "  Aw = Ad(w)\n",
    "  results = {\"Laplacian\" : Lw, \"Adjacency\" : Aw, \"w\" : w, \"lambd\" : lambd, \"U\" : U,\\\n",
    "                  \"elapsed_time\" : time_seq, \"convergence\" : has_w_converged,\\\n",
    "                  \"beta_seq\" : beta_seq}\n",
    "  return results\n",
    "\n",
    "def learn_bipartite_graph(S, is_data_matrix = False, z = 0, nu = 1e4, alpha = 0.,\n",
    "                                  w0 = \"naive\", m = 7, maxiter = 1e4, abstol = 1e-6, reltol = 1e-4,\n",
    "                                  record_weights = False, verbose = True):\n",
    "  if is_data_matrix or S.shape[0] != S.shape[1]:\n",
    "    A = build_initial_graph(S, m = m)\n",
    "    D =  np.diag(.5 * (np.sum(A,axis=1) + np.sum(A,axis=0)))\n",
    "    L = D - .5 * (A + A.T)\n",
    "    S = np.linalg.pinv(L)\n",
    "    is_data_matrix = True\n",
    "  # number of nodes\n",
    "  n = S.shape[0]\n",
    "  # note now that S is always some sort of similarity matrix\n",
    "  J = np.ones([n,n])/n\n",
    "  # l1-norm penalty factor\n",
    "  H = alpha * (2 * np.eye(n) - np.ones([n, n]))\n",
    "  K = S + H\n",
    "  # compute initial guess\n",
    "  if is_data_matrix:\n",
    "    Sinv = L\n",
    "  else:\n",
    "    Sinv = np.linalg.pinv(S)\n",
    "  # if w0 is either \"naive\" or \"qp\", compute it, else return w0\n",
    "  w0 = w_init(w0, Sinv)\n",
    "  Lips = 1 / np.linalg.eigh(La(w0) + J)[0][0]\n",
    "  # compute quantities on the initial guess\n",
    "  Aw0 = Ad(w0)\n",
    "  V0 = bipartite_V_update(Aw0, z)\n",
    "  psi0 = bipartite_psi_update(V0, Aw0)\n",
    "  Lips_seq = [Lips]\n",
    "  time_seq = [0]\n",
    "  start_time = time()\n",
    "  ll0 = bipartite_likelihood(Lw = La(w0), K = K, J = J)\n",
    "  fun0 = ll0 + bipartite_prior(nu = nu, Aw = Aw0, psi = psi0, V = V0)\n",
    "  fun_seq = [fun0]\n",
    "  ll_seq = [ll0]\n",
    "  for i in np.arange(maxiter):\n",
    "    # we need to make sure that the Lipschitz constant is large enough\n",
    "    # in order to avoid divergence\n",
    "    while 1:\n",
    "      # compute the update for w\n",
    "      w = bipartite_w_update(w = w0, Aw = Aw0, V = V0, nu = nu, psi = psi0,\n",
    "                              K = K, J = J, Lips = Lips)\n",
    "      # compute the objective function at the updated value of w\n",
    "      fun_t=bipartite_obj_fun(Aw = Ad(w), Lw = La(w), V = V0, psi = psi0,\n",
    "                        K = K, J = J, nu = nu)\n",
    "      \"\"\"fun_t = tryCatch({#TODO\n",
    "                   bipartite.obj_fun(Aw = A(w), Lw = L(w), V = V0, psi = psi0,\n",
    "                                     K = K, J = J, nu = nu)\n",
    "                 }, warning = function(warn) return(Inf), error = function(err) return(Inf)\n",
    "               )\"\"\"\n",
    "      # check if the previous value of the objective function is\n",
    "      # smaller than the current one\n",
    "      Lips_seq.append(Lips)\n",
    "      if fun0 < fun_t:\n",
    "        # in case it is in fact larger, then increase Lips and recompute w\n",
    "        Lips = 2 * Lips\n",
    "    else:\n",
    "        # otherwise decrease Lips and get outta here!\n",
    "        Lips = .5 * Lips\n",
    "        if Lips < 1e-12:\n",
    "          Lips = 1e-12\n",
    "        break\n",
    "    Lw = La(w)\n",
    "    Aw = Ad(w)\n",
    "    V = bipartite_V_update(Aw = Aw, z = z)\n",
    "    psi = bipartite_psi_update(V = V, Aw = Aw)\n",
    "    # compute negloglikelihood and objective function values\n",
    "    ll = bipartite_likelihood(Lw = Lw, K = K, J = J)\n",
    "    fun = ll + bipartite_prior(nu = nu, Aw = Aw, psi = psi, V = V)\n",
    "    # save measurements of time and objective functions\n",
    "    time_seq.append(time()- start_time)\n",
    "    ll_seq.append(ll)\n",
    "    fun_seq.append(fun)\n",
    "    # compute the relative error and check the tolerance on the Adjacency\n",
    "    # matrix and on the objective function\n",
    "    # check for convergence\n",
    "    werr = abs(w0 - w)\n",
    "    has_w_converged = (np.all(werr <= .5 * reltol * (w + w0)) or np.all(werr <= abstol))\n",
    "    if (has_w_converged):\n",
    "      break\n",
    "    # update estimates\n",
    "    fun0 = fun\n",
    "    w0 = w\n",
    "    V0 = V\n",
    "    psi0 = psi\n",
    "    Aw0 = Aw\n",
    "  results = {\"Laplacian\" : Lw, \"Adjacency\" : Aw, \"obj_fun\" : fun_seq, \"loglike\" : ll_seq, \"w\" : w,\n",
    "                  \"psi\" : psi, \"V\" : V, \"elapsed_time\" : time_seq, \"Lips\" : Lips,\n",
    "                  \"Lips_seq\" : Lips_seq, \"convergence\" : (i < maxiter), \"nu\" : nu}\n",
    "  return results\n",
    "\n",
    "\n",
    "def learn_bipartite_k_component_graph(S, is_data_matrix = False, z = 0, k = 1,\\\n",
    "                                              w0 = \"naive\", m = 7, alpha = 0., beta = 1e4,\\\n",
    "                                              rho = 1e-2, fix_beta = True, beta_max = 1e6, nu = 1e4,\\\n",
    "                                              lb = 0, ub = 1e4, maxiter = 1e4, abstol = 1e-6,\\\n",
    "                                              reltol = 1e-4, eigtol = 1e-9,\\\n",
    "                                              record_weights = False, record_objective = False, verbose = True):\n",
    "  if is_data_matrix or S.shape[0] != S.shape[1]:\n",
    "    A = build_initial_graph(S, m = m)\n",
    "    D =  np.diag(.5 * (np.sum(A,axis=1) + np.sum(A,axis=0)))\n",
    "    # L = D - .5 * (A + A.T)\n",
    "    S = np.linalg.pinv(L)\n",
    "    is_data_matrix = True\n",
    "  # number of nodes\n",
    "  n = S.shape[0]\n",
    "  # note now that S is always some sort of similarity matrix\n",
    "  J = np.ones([n,n])/n\n",
    "  # l1-norm penalty factor\n",
    "  H = alpha * (2 * np.eye(n) - np.ones([n, n]))\n",
    "  K = S + H\n",
    "  # compute initial guess\n",
    "  if is_data_matrix:\n",
    "    Sinv = L\n",
    "  else:\n",
    "    Sinv = np.linalg.pinv(S)\n",
    "  # if w0 is either \"naive\" or \"qp\", compute it, else return w0\n",
    "  w0 = w_init(w0, Sinv)\n",
    "  # compute quantities on the initial guess\n",
    "  Aw0 = Ad(w0)\n",
    "  Lw0 = La(w0)\n",
    "  V0 = joint_V_update(Aw0, z)\n",
    "  psi0 = bipartite_psi_update(V0, Aw0)\n",
    "  U0 = joint_U_update(Lw0, k)\n",
    "  lambda0 = laplacian_lambda_update(lb, ub, beta, U0, Lw0, k)\n",
    "  beta_seq = [beta]\n",
    "  time_seq = [0]\n",
    "  start_time = time()\n",
    "  for i in np.arange(maxiter):\n",
    "    w = joint_w_update(w0, Lw0, Aw0, U0, V0, lambda0, psi0, beta, nu, K)\n",
    "    Lw = La(w)\n",
    "    Aw = Ad(w)\n",
    "    U = joint_U_update(Lw, k)\n",
    "    V = joint_V_update(Aw, z)\n",
    "    lambd = laplacian_lambda_update(lb, ub, beta, U, Lw, k)\n",
    "    psi = bipartite_psi_update(V, Aw)\n",
    "    time_seq.append(time()-start_time)\n",
    "    werr = abs(w0 - w)\n",
    "    has_w_converged = (np.all(werr <= .5 * reltol * (w + w0)) or np.all(werr <= abstol))\n",
    "    time_seq.append(time()-start_time)\n",
    "    eigvals = np.linalg.eigh(Lw)[0]\n",
    "    if not(fix_beta):\n",
    "      n_zero_eigenvalues = sum(abs(eigvals) < eigtol)\n",
    "      if (k < n_zero_eigenvalues):\n",
    "        beta = (1 + rho) * beta\n",
    "      elif (k > n_zero_eigenvalues):\n",
    "        beta = beta / (1 + rho)\n",
    "      if (beta > beta_max):\n",
    "        beta = beta_max\n",
    "      beta_seq.append(beta)\n",
    "    if (has_w_converged):\n",
    "      break\n",
    "    # update estimates\n",
    "    w0 = w\n",
    "    U0 = U\n",
    "    V0 = V\n",
    "    lambda0 = lambd\n",
    "    psi0 = psi\n",
    "    Lw0 = Lw\n",
    "    Aw0 = Aw\n",
    "  results = {\"Laplacian\" : Lw, \"Adjacency\" : Aw, \"w\" : w, \"psi\" : psi,\n",
    "                  \"lambd\" : lambd, \"V\" : V, \"U\" : U, \"elapsed_time\" : time_seq,\n",
    "                  \"beta_seq\" : beta_seq, \"convergence\" : has_w_converged}\n",
    "  return(results)\n",
    "\n",
    "def nb_connected_component(L):\n",
    "    return np.sum(np.linalg.eigh(L)[0]<10**-12)\n",
    "\n",
    "def is_bipartite(A):\n",
    "    n=A.shape[0]\n",
    "    co=[-1]*n\n",
    "    def parc(u):\n",
    "        for v in range(n):\n",
    "            if A[u][v]>0:\n",
    "                if co[v]==-1:\n",
    "                    co[v]=1-co[u]\n",
    "                    if not(parc(v)):\n",
    "                        return False\n",
    "                elif co[v]+co[u]!=1:\n",
    "                    return False\n",
    "        return True\n",
    "    for u in range(n):\n",
    "        if co[u]==-1:\n",
    "            co[u]=0\n",
    "            if not(parc(u)):\n",
    "                return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2a1063b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "dataset = os.path.join(os.getcwd(),'CITESEER')\n",
    "dataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "dataset= Planetoid(root=dataset, name='CITESEER')\n",
    "# x = dataset[0].x.detach().cpu().numpy()\n",
    "X = dataset[0].x\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f570130b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3327, 3703]) torch.Size([3327, 3327])\n",
      "torch.Size([3327, 3703]) torch.Size([3327, 3327])\n",
      "torch.Size([3327, 3327])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "adj = to_dense_adj(dataset[0].edge_index)\n",
    "adj = adj[0]\n",
    "labels = dataset[0].y\n",
    "labels = labels.numpy()\n",
    "\n",
    "X = dataset[0].x\n",
    "X = X.to_dense()\n",
    "N = X.shape[0]\n",
    "NO_OF_CLASSES =  len(set(np.array(dataset[0].y)))\n",
    "\n",
    "print(X.shape, adj.shape)\n",
    "\n",
    "nn = int(1*N)\n",
    "X = X[:nn,:]\n",
    "adj = adj[:nn,:nn]\n",
    "labels = labels[:nn]\n",
    "print(X.shape,adj.shape)\n",
    "def get_laplacian(adj):\n",
    "    b=torch.ones(adj.shape[0])\n",
    "    return torch.diag(adj@b)-adj\n",
    "\n",
    "theta = get_laplacian(adj)\n",
    "print(theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aeda2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "L=theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc7b6e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/10000 [01:23<21:16:35,  7.67s/it]"
     ]
    }
   ],
   "source": [
    "# n_samples = 100 * n_feats   #(2000)\n",
    "# # compute the laplacian and correlation matrices\n",
    "# lap = np.diag(adj.sum(axis=0)) - adj\n",
    "# theta = np.linalg.pinv(lap)\n",
    "# # generate samples\n",
    "# x = np.random.multivariate_normal(np.zeros(n_feats), theta, size=n_samples).T\n",
    "\n",
    "\n",
    "# # learn the laplacian and adjacency matrices\n",
    "res_denoising = learn_k_component_graph(adj,theta, X.T, k=4, maxiter=10000)\n",
    "if res_denoising['convergence']: print(\"The optimization converged!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe259f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
